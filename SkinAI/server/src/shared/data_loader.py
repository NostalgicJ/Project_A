"""
ì‹¤ì œ ì œí’ˆ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ë°ì´í„° ë¡œë” ë° ë¶„í•  ìŠ¤í¬ë¦½íŠ¸
í›ˆë ¨/í…ŒìŠ¤íŠ¸/ê²€ì¦ ì„¸íŠ¸ë¥¼ 8:1:1 ë¹„ìœ¨ë¡œ ë¶„í• 
"""
import pandas as pd
import numpy as np
import pickle
import json
from typing import List, Dict, Tuple, Set
from pathlib import Path
import random
from collections import Counter
from datetime import datetime

class RealDataLoader:
    """ì‹¤ì œ ì œí’ˆ ë°ì´í„° ë¡œë”"""
    
    def __init__(self, 
                 products_file: str = "data/processed/processed_cosmetics_final_2.csv",
                 ingredients_file: str = "data/processed/integrated_product_ingredient_normalized_2.csv",
                 master_ingredients_file: str = "data/processed/coos_master_ingredients_cleaned.csv",
                 public_ingredients_file: str = "data/raw/public_ingredients.json"): # [ìˆ˜ì •] ê³µìš© ì„±ë¶„ íŒŒì¼ ê²½ë¡œ ì¶”ê°€
        self.products_file = products_file
        self.ingredients_file = ingredients_file
        self.master_ingredients_file = master_ingredients_file
        self.public_ingredients_file = public_ingredients_file # [ìˆ˜ì •]
        
        self.products_df = None
        self.ingredients_df = None
        self.master_ingredients_df = None
        self.public_ingredients_list = None # [ìˆ˜ì •] JSON ë°ì´í„° ì €ì¥ìš©
        
        self.vocab = None
        self.vocab_to_idx = None
        self.idx_to_vocab = None
        
    def load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        print("ğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # ì œí’ˆ ë°ì´í„° ë¡œë“œ
        self.products_df = pd.read_csv(self.products_file)
        print(f"âœ… ì œí’ˆ ë°ì´í„°: {len(self.products_df)}ê°œ")
        
        # ì„±ë¶„ ë°ì´í„° ë¡œë“œ
        if Path(self.ingredients_file).exists():
            self.ingredients_df = pd.read_csv(self.ingredients_file)
            print(f"âœ… ì„±ë¶„ ë°ì´í„°: {len(self.ingredients_df)}ê°œ")
        
        # ë§ˆìŠ¤í„° ì„±ë¶„ ë¡œë“œ (ì°¸ê³ ìš©ìœ¼ë¡œ ë¡œë“œëŠ” ìœ ì§€)
        if Path(self.master_ingredients_file).exists():
            self.master_ingredients_df = pd.read_csv(self.master_ingredients_file)
            print(f"âœ… ë§ˆìŠ¤í„° ì„±ë¶„: {len(self.master_ingredients_df)}ê°œ")

        # --- [ìˆ˜ì •] ---
        # ê³µìš© ì„±ë¶„ ì‚¬ì „ ë¡œë“œ (JSON)
        if Path(self.public_ingredients_file).exists():
            try:
                with open(self.public_ingredients_file, 'r', encoding='utf-8') as f:
                    self.public_ingredients_list = json.load(f)
                print(f"âœ… ê³µìš© ì„±ë¶„ ì‚¬ì „: {len(self.public_ingredients_list)}ê°œ")
            except json.JSONDecodeError:
                print(f"âš ï¸ ê³µìš© ì„±ë¶„ ì‚¬ì „ íŒŒì¼({self.public_ingredients_file})ì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
                self.public_ingredients_list = []
            except Exception as e:
                print(f"âš ï¸ ê³µìš© ì„±ë¶„ ì‚¬ì „ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
                self.public_ingredients_list = []
        else:
            print(f"âš ï¸ ê³µìš© ì„±ë¶„ ì‚¬ì „ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.public_ingredients_file}")
            self.public_ingredients_list = []
        # --- [ìˆ˜ì • ì™„ë£Œ] ---
        
        return self
    
    # --- [ìˆ˜ì •] ---
    # ì–´íœ˜ ì‚¬ì „ êµ¬ì¶• ë¡œì§ì„ public_ingredients.json ê¸°ì¤€ìœ¼ë¡œ ë³€ê²½
    def build_vocabulary(self, min_freq: int = 1) -> List[str]:
        """ê³µìš© ì„±ë¶„ ì‚¬ì „(JSON)ì„ ê¸°ë°˜ìœ¼ë¡œ ì–´íœ˜ ì‚¬ì „ êµ¬ì¶•"""
        print("ğŸ”¤ ì„±ë¶„ ì–´íœ˜ ì‚¬ì „ êµ¬ì¶• ì¤‘ (ê³µìš© ì„±ë¶„ ì‚¬ì „ ê¸°ì¤€)...")
        
        ingredient_counts = Counter()
        
        if self.public_ingredients_list is None or len(self.public_ingredients_list) == 0:
            print("âš ï¸ 'public_ingredients.json'ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        else:
            # public_ingredients.jsonì˜ 'í•œê¸€ëª…'ì„ ì–´íœ˜ ì‚¬ì „ìœ¼ë¡œ ì‚¬ìš©
            for item in self.public_ingredients_list:
                ing = item.get('í•œê¸€ëª…')
                if ing:
                    ing = str(ing).strip()
                    if len(ing) > 1:
                        ingredient_counts[ing] += 1 # 1íšŒ ì¹´ìš´íŠ¸
        
        # ìµœì†Œ ë¹ˆë„ í•„í„°ë§ (ì‚¬ì‹¤ìƒ min_freq=1ì´ë©´ ëª¨ë“  ì„±ë¶„ í¬í•¨)
        filtered_ingredients = [
            ing for ing, count in ingredient_counts.items() 
            if count >= min_freq and len(ing) > 1
        ]
        
        # ë¹ˆë„ìˆœ ì •ë ¬
        filtered_ingredients.sort(key=lambda x: ingredient_counts[x], reverse=True)
        
        # <UNK> í† í° ì¶”ê°€
        self.vocab = ['<UNK>'] + filtered_ingredients
        self.vocab_to_idx = {ing: idx for idx, ing in enumerate(self.vocab)}
        self.idx_to_vocab = {idx: ing for ing, idx in self.vocab_to_idx.items()}
        
        print(f"âœ… ì–´íœ˜ ì‚¬ì „ êµ¬ì¶• ì™„ë£Œ: {len(self.vocab)}ê°œ ì„±ë¶„")
        print(f"   - <UNK> í† í°: 1ê°œ")
        print(f"   - ì‹¤ì œ ì„±ë¶„: {len(filtered_ingredients)}ê°œ")
        print(f"   - ìµœì†Œ ë¹ˆë„: {min_freq}íšŒ ì´ìƒ (JSON ê¸°ì¤€)")
        
        return self.vocab
    # --- [ìˆ˜ì • ì™„ë£Œ] ---
    
    # --- [ìˆ˜ì •] ---
    # ingredients_dfì˜ ì‹¤ì œ ì»¬ëŸ¼ëª…ì„ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •
    def extract_product_formulas(self) -> List[Tuple[List[str], str]]:
        """ì œí’ˆë³„ ì„±ë¶„ í¬ë®¬ëŸ¬ ì¶”ì¶œ (ì •ì œëœ 'ingredients_df' ê¸°ì¤€)"""
        print("ğŸ“ ì œí’ˆë³„ ì„±ë¶„ í¬ë®¬ëŸ¬ ì¶”ì¶œ ì¤‘...")
        
        if self.ingredients_df is None:
            print("âš ï¸ 'ingredients_df'ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []

        # [ìˆ˜ì •] 'ingredients_df'ì˜ ì‹¤ì œ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€ê²½
        # 'ì‚¬ìš©_ì›ë£Œëª…'ì´ 'public_ingredients.json'ì˜ 'í•œê¸€ëª…'ê³¼ ì¼ì¹˜í•œë‹¤ê³  ê°€ì •
        product_id_cols = ['ë¸Œëœë“œëª…', 'ì œí’ˆëª…'] 
        ingredient_col = 'ì‚¬ìš©_ì›ë£Œëª…' # [ìˆ˜ì •] COOS_ì›ë£Œëª… -> ì‚¬ìš©_ì›ë£Œëª…
        
        required_cols = product_id_cols + [ingredient_col]
        
        if not all(col in self.ingredients_df.columns for col in required_cols):
            print(f"âš ï¸ 'ingredients_df'ì— {required_cols} ì»¬ëŸ¼ì´ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤. ì»¬ëŸ¼ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            print(f"   (í˜„ì¬ ì»¬ëŸ¼: {self.ingredients_df.columns.tolist()})")
            return []

        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•´ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        df_subset = self.ingredients_df[required_cols].dropna()

        # ì–´íœ˜ ì‚¬ì „ì— ìˆëŠ” ìœ íš¨í•œ ì„±ë¶„ë§Œ í•„í„°ë§
        print("   - ì–´íœ˜ ì‚¬ì „ ê¸°ì¤€ìœ¼ë¡œ ì„±ë¶„ í•„í„°ë§ ì¤‘...")
        
        # ì–´íœ˜ ì‚¬ì „(self.vocab_to_idx)ì´ Setì´ë©´ ë” ë¹ ë¦…ë‹ˆë‹¤.
        vocab_set = set(self.vocab_to_idx.keys())
        
        valid_ingredients_mask = df_subset[ingredient_col].apply(
            lambda ing: str(ing).strip() in vocab_set and len(str(ing).strip()) > 1
        )
        df_filtered = df_subset[valid_ingredients_mask].copy() # SettingWithCopyWarning ë°©ì§€

        # ì œí’ˆ IDë³„ë¡œ ì„±ë¶„ ê·¸ë£¹í•‘
        print("   - ì œí’ˆë³„ ì„±ë¶„ ê·¸ë£¹í•‘ ì¤‘...")
        
        def create_product_id(row):
            # ì›ë³¸ ì½”ë“œì˜ ID ìƒì„± ë°©ì‹
            return f"{row.get(product_id_cols[0], 'Unknown')}_{row.get(product_id_cols[1], 'Unknown')}"

        # ê³ ìœ  ID ìƒì„±
        df_filtered['product_id'] = df_filtered.apply(create_product_id, axis=1)

        # ê·¸ë£¹í•‘í•˜ì—¬ setìœ¼ë¡œ ë§Œë“  í›„ listë¡œ ë³€í™˜ (ì¤‘ë³µ ì„±ë¶„ ì œê±°)
        grouped = df_filtered.groupby('product_id')[ingredient_col].apply(set).apply(list)
        
        # 2ê°œ ì´ìƒì˜ ì„±ë¶„ì„ ê°€ì§„ ì œí’ˆë§Œ í¬ë®¬ëŸ¬ë¡œ ì¸ì • (ìŒì„ ë§Œë“¤ì–´ì•¼ í•˜ë¯€ë¡œ)
        formulas = [
            (ingredients, product_id) 
            for product_id, ingredients in grouped.items()
            if len(ingredients) > 1
        ]
        
        print(f"âœ… ì„±ë¶„ í¬ë®¬ëŸ¬ ì¶”ì¶œ ì™„ë£Œ: {len(formulas)}ê°œ ì œí’ˆ (ìœ íš¨ ì„±ë¶„ 2ê°œ ì´ìƒ)")
        return formulas
    # --- [ìˆ˜ì • ì™„ë£Œ] ---

    def create_ingredient_pairs(self, formulas: List[Tuple[List[str], str]]) -> List[Tuple[str, str, float, float]]:
        """ì„±ë¶„ ìŒ ë°ì´í„° ìƒì„± (ìœ„í—˜ë„ ë° ì‹œë„ˆì§€ ë¼ë²¨ í¬í•¨)"""
        print("ğŸ”— ì„±ë¶„ ìŒ ë°ì´í„° ìƒì„± ì¤‘...")
        
        # ê·œì¹™ íŒŒì¼ ë¡œë“œ
        rules_file = Path("config/ingredient_rules.json")
        dangerous_combinations = {}
        synergy_combinations = {}
        
        if rules_file.exists():
            try:
                with open(rules_file, 'r', encoding='utf-8') as f:
                    rules = json.load(f)
            except Exception as e:
                print(f"âš ï¸ 'ingredient_rules.json' íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
                rules = {}
            
            # ì„±ë¶„ ê³„ì—´ ë§¤í•‘
            ingredient_families = rules.get('ingredient_families', {})
            vocab_set = set(self.vocab_to_idx.keys()) # ë¹ ë¥¸ ì¡°íšŒë¥¼ ìœ„í•´ Set ì‚¬ìš©

            # ìœ„í—˜í•œ ì¡°í•©
            for combo in rules.get('dangerous_combinations', []):
                family1 = combo.get('family1')
                family2 = combo.get('family2')
                danger_level = combo.get('danger_level', 0.5)
                
                if not family1 or not family2: continue
                
                ing1_list_from_family = ingredient_families.get(family1, [])
                ing2_list_from_family = ingredient_families.get(family2, [])

                for ing1 in ing1_list_from_family:
                    if ing1 in vocab_set:
                        for ing2 in ing2_list_from_family:
                            if ing2 in vocab_set:
                                pair = tuple(sorted([ing1, ing2]))
                                dangerous_combinations[pair] = danger_level
            
            # ì‹œë„ˆì§€ ì¡°í•©
            for combo in rules.get('synergy_combinations', []):
                family1 = combo.get('family1')
                family2 = combo.get('family2')
                synergy_level = combo.get('synergy_level', 0.5)

                if not family1 or not family2: continue

                ing1_list_from_family = ingredient_families.get(family1, [])
                ing2_list_from_family = ingredient_families.get(family2, [])

                for ing1 in ing1_list_from_family:
                    if ing1 in vocab_set:
                        for ing2 in ing2_list_from_family:
                            if ing2 in vocab_set:
                                pair = tuple(sorted([ing1, ing2]))
                                synergy_combinations[pair] = synergy_level
        
        else:
            print("âš ï¸ 'config/ingredient_rules.json' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìœ„í—˜/ì‹œë„ˆì§€ ë¼ë²¨ì´ 0.0ìœ¼ë¡œ ì„¤ì •ë©ë‹ˆë‹¤.")

        pairs = []
        
        for formula, product_id in formulas:
            for i, ing1 in enumerate(formula):
                for ing2 in formula[i+1:]:
                    pair = tuple(sorted([ing1, ing2]))
                    
                    # ìœ„í—˜ë„ ë° ì‹œë„ˆì§€ ë¼ë²¨ (ingredient_rules.jsonì— ìˆëŠ” ê²ƒë§Œ ì •ë‹µ ë ˆì´ë¸”)
                    danger = dangerous_combinations.get(pair, 0.0)
                    synergy = synergy_combinations.get(pair, 0.0)
                    
                    # ë¼ë²¨ì´ ìˆëŠ”ì§€ í™•ì¸ (ìœ„í—˜ ë˜ëŠ” ì‹œë„ˆì§€ê°€ 0ë³´ë‹¤ í¬ë©´ ë¼ë²¨ ìˆìŒ)
                    has_label = (danger > 0.0) or (synergy > 0.0)
                    
                    # ë¼ë²¨ì´ ì—†ëŠ” ê²½ìš° -1ë¡œ í‘œì‹œ (ë¯¸í™•ì¸ ìƒíƒœ)
                    if not has_label:
                        danger = -1.0  # ë¼ë²¨ ì—†ìŒ í‘œì‹œ
                        synergy = -1.0  # ë¼ë²¨ ì—†ìŒ í‘œì‹œ
                    
                    pairs.append((ing1, ing2, danger, synergy))
        
        labeled_count = sum(1 for _, _, d, s in pairs if d > 0 or s > 0)
        unlabeled_count = len(pairs) - labeled_count
        
        print(f"âœ… ì„±ë¶„ ìŒ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(pairs)}ê°œ ìŒ")
        print(f"   - ë¼ë²¨ì´ ìˆëŠ” ì¡°í•©: {labeled_count}ê°œ (ì •ë‹µ ë ˆì´ë¸”)")
        print(f"     * ìœ„í—˜í•œ ì¡°í•©: {sum(1 for _, _, d, _ in pairs if d > 0)}ê°œ")
        print(f"     * ì‹œë„ˆì§€ ì¡°í•©: {sum(1 for _, _, _, s in pairs if s > 0)}ê°œ")
        print(f"   - ë¼ë²¨ì´ ì—†ëŠ” ì¡°í•©: {unlabeled_count}ê°œ (ë¯¸í™•ì¸ ìƒíƒœ)")
        print(f"   âš ï¸  ë¼ë²¨ì´ ì—†ëŠ” ì¡°í•©ì€ í•™ìŠµ ì‹œ ì†ì‹¤ ê³„ì‚°ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.")
        
        return pairs
    
    def split_data(self, 
                   pairs: List[Tuple[str, str, float, float]],
                   train_ratio: float = 0.8,
                   test_ratio: float = 0.1,
                   val_ratio: float = 0.1,
                   random_seed: int = 42) -> Tuple[List, List, List]:
        """ë°ì´í„° ë¶„í•  (8:1:1)"""
        print(f"ğŸ“Š ë°ì´í„° ë¶„í•  ì¤‘... (í›ˆë ¨:{train_ratio}, í…ŒìŠ¤íŠ¸:{test_ratio}, ê²€ì¦:{val_ratio})")
        
        total = len(pairs)
        if total == 0:
            print("âš ï¸ ë¶„í• í•  ë°ì´í„°(ìŒ)ê°€ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
            print(f"âœ… ë°ì´í„° ë¶„í•  ì™„ë£Œ:")
            print(f"   - í›ˆë ¨ ì„¸íŠ¸: 0ê°œ (0.0%)")
            print(f"   - í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: 0ê°œ (0.0%)")
            print(f"   - ê²€ì¦ ì„¸íŠ¸: 0ê°œ (0.0%)")
            return [], [], []
        
        random.seed(random_seed)
        np.random.seed(random_seed)
        
        # ì…”í”Œ
        shuffled = pairs.copy()
        random.shuffle(shuffled)
        
        # ë¶„í• 
        train_end = int(total * train_ratio)
        test_end = train_end + int(total * test_ratio)
        
        train_data = shuffled[:train_end]
        test_data = shuffled[train_end:test_end]
        val_data = shuffled[test_end:]
        
        print(f"âœ… ë°ì´í„° ë¶„í•  ì™„ë£Œ:")
        print(f"   - í›ˆë ¨ ì„¸íŠ¸: {len(train_data)}ê°œ ({len(train_data)/total:.1%})")
        print(f"   - í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: {len(test_data)}ê°œ ({len(test_data)/total:.1%})")
        print(f"   - ê²€ì¦ ì„¸íŠ¸: {len(val_data)}ê°œ ({len(val_data)/total:.1%})")
        
        return train_data, test_data, val_data
    
    def save_data_splits(self, 
                        train_data: List,
                        test_data: List,
                        val_data: List,
                        output_dir: str = "data/splits"):
        """ë°ì´í„° ë¶„í•  ì €ì¥"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ë°ì´í„° ì €ì¥
        with open(output_path / f"train_data_{timestamp}.pkl", 'wb') as f:
            pickle.dump(train_data, f)
        
        with open(output_path / f"test_data_{timestamp}.pkl", 'wb') as f:
            pickle.dump(test_data, f)
        
        with open(output_path / f"val_data_{timestamp}.pkl", 'wb') as f:
            pickle.dump(val_data, f)
        
        # ì–´íœ˜ ì‚¬ì „ ì €ì¥
        with open(output_path / f"vocab_{timestamp}.pkl", 'wb') as f:
            pickle.dump({
                'vocab': self.vocab,
                'vocab_to_idx': self.vocab_to_idx,
                'idx_to_vocab': self.idx_to_vocab
            }, f)
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'timestamp': timestamp,
            'vocab_size': len(self.vocab),
            'train_size': len(train_data),
            'test_size': len(test_data),
            'val_size': len(val_data),
            'total_pairs': len(train_data) + len(test_data) + len(val_data)
        }
        
        with open(output_path / f"metadata_{timestamp}.json", 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ë°ì´í„° ë¶„í•  ì €ì¥ ì™„ë£Œ: {output_dir}")
        print(f"   - íƒ€ì„ìŠ¤íƒ¬í”„: {timestamp}")
        
        return timestamp


if __name__ == "__main__":
    # ë°ì´í„° ë¡œë“œ ë° ë¶„í•  ì‹¤í–‰ã…ˆ
    loader = RealDataLoader(
        # í•„ìš”í•œ ê²½ìš° íŒŒì¼ ê²½ë¡œë¥¼ ì—¬ê¸°ì„œ ì§ì ‘ ì§€ì •
        # products_file="...",
        # ingredients_file="...",
        public_ingredients_file="data/raw/public_ingredients.json"
    )
    loader.load_data()
    vocab = loader.build_vocabulary(min_freq=1)
    
    formulas = loader.extract_product_formulas()
    pairs = loader.create_ingredient_pairs(formulas)
    
    train_data, test_data, val_data = loader.split_data(pairs, train_ratio=0.8, test_ratio=0.1, val_ratio=0.1)
    
    if len(train_data) > 0:
        timestamp = loader.save_data_splits(train_data, test_data, val_data)
        print(f"\nğŸ‰ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ! íƒ€ì„ìŠ¤íƒ¬í”„: {timestamp}")
    else:
        print("\nâš ï¸ ìƒì„±ëœ ë°ì´í„°ê°€ ì—†ì–´ íŒŒì¼ ì €ì¥ì„ ìŠ¤í‚µí•©ë‹ˆë‹¤.")
