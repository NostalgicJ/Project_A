#!/usr/bin/env python3
"""
ì˜¬ë¦¬ë¸Œì˜ ì œí’ˆ ë°ì´í„° ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸

ê¸°ëŠ¥:
1. JSON íŒŒì¼ì—ì„œ ì œí’ˆ ì •ë³´ íŒŒì‹± (ë¸Œëœë“œëª…, ì œí’ˆëª…, ì„±ë¶„ë¦¬ìŠ¤íŠ¸)
2. ì œí’ˆëª…ì—ì„œ ë¶ˆí•„ìš”í•œ í‚¤ì›Œë“œ ì œê±° (ê¸°íš, ì¦ì •, ì˜¬ì˜í”½ ë“±)
3. ì„±ë¶„ ì •ê·œí™” - ê³µê³µë°ì´í„°í¬í„¸ API ì„±ë¶„ ë°ì´í„°ì™€ ë§¤ì¹­
4. ë¯¸í™•ì¸ ì„±ë¶„ ë¶„ë¦¬
5. ê¸°íš ìƒí’ˆ ì²˜ë¦¬ (í•œ ì œí’ˆì— ì—¬ëŸ¬ ì•„ì´í…œ í¬í•¨ëœ ê²½ìš°)
"""

import json
import pandas as pd
import re
from typing import List, Dict, Tuple, Set
from pathlib import Path
import requests
import time

class OliveYoungDataPreprocessor:
    """ì˜¬ë¦¬ë¸Œì˜ ë°ì´í„° ì „ì²˜ë¦¬ê¸°"""
    
    def __init__(self):
        self.unwanted_keywords = [
            'ê¸°íš', 'ì¦ì •', 'ì˜¬ì˜í”½', 'PICK', 'í™”ì˜ë¨¹', 'ë¦¬í•„ê¸°íš',
            'ë”ë¸”ê¸°íš', 'í•œì •ê¸°íš', 'ë‹¨ë…', '1+1', '2+1', '3+1',
            'ë¦¬í•„', 'ê¸°í”„íŠ¸', 'ì¦ì •í’ˆ', 'ì‚¬ì€í’ˆ', 'í”„ë¦¬ë¯¸ì—„',
            'ì—°ì˜ˆì¸', 'ìœ ëª…ì¸', 'ì¸ê¸°', 'ë² ìŠ¤íŠ¸', 'NEW',
            'ì‹ ìƒ', 'ì¶œì‹œ', 'ëŸ°ì¹­', 'ì˜¤í”ˆ', 'íŠ¹ê°€',
            '[', ']', '(', ')'
        ]
        
        self.all_ingredients = set()  # ê³µê³µë°ì´í„° APIì—ì„œ ë°›ì€ ì „ì²´ ì„±ë¶„
        self.api_ingredients = None
        
    def load_public_api_ingredients(self):
        """
        ê³µê³µë°ì´í„° í¬í„¸ APIì—ì„œ ì „ì²´ ì„±ë¶„ ë°ì´í„° ë¡œë“œ
        """
        print("ğŸ“¡ ì„±ë¶„ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # 1. ê³µê³µë°ì´í„° APIì—ì„œ ë‹¤ìš´ë¡œë“œí•œ ë°ì´í„° ìš°ì„  ì‚¬ìš©
        try:
            public_df = pd.read_csv('data/raw/public_ingredients.csv')
            # í•œê¸€ëª…ê³¼ ì˜ë¬¸ëª…ì„ ëª¨ë‘ í¬í•¨
            ingredients = set()
            ingredients.update(public_df['í•œê¸€ëª…'].dropna().astype(str))
            ingredients.update(public_df['ì˜ë¬¸ëª…'].dropna().astype(str))
            
            if len(ingredients) > 0:
                self.all_ingredients = ingredients
                print(f"âœ… ê³µê³µë°ì´í„° API ì„±ë¶„ ë¡œë“œ: {len(self.all_ingredients)}ê°œ")
                return
        except Exception as e:
            print(f"âš ï¸ ê³µê³µë°ì´í„° íŒŒì¼ ì—†ìŒ: {e}")
        
        # 2. COOS ë§ˆìŠ¤í„° ë°ì´í„° ì‚¬ìš© (ë°±ì—…)
        try:
            master_df = pd.read_csv('data/raw/coos_master_ingredients_cleaned.csv')
            self.all_ingredients = set(master_df['ì›ë£Œëª…_ì •ì œë¨'].dropna())
            print(f"âœ… COOS ë§ˆìŠ¤í„° ë°ì´í„° ì‚¬ìš©: {len(self.all_ingredients)}ê°œ")
        except Exception as e:
            print(f"âŒ ì„±ë¶„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.all_ingredients = set()
    
    def clean_product_name(self, product_name: str) -> str:
        """
        ì œí’ˆëª…ì—ì„œ ë¶ˆí•„ìš”í•œ í‚¤ì›Œë“œ ì œê±°
        
        Args:
            product_name: ì›ë³¸ ì œí’ˆëª…
            
        Returns:
            ì •ì œëœ ì œí’ˆëª…
        """
        cleaned = product_name
        
        # ëŒ€ê´„í˜¸ ë‚´ìš© ì œê±°
        cleaned = re.sub(r'\[.*?\]', '', cleaned)
        
        # ê´„í˜¸ ë‚´ìš© ì œê±° (ë‹¨, ì‚¬ì´ì¦ˆ ì •ë³´ëŠ” ìœ ì§€)
        cleaned = re.sub(r'\([^)]*ml[^)]*\)', '', cleaned)
        cleaned = re.sub(r'\([^)]*\)', '', cleaned)
        
        # ë¶ˆí•„ìš”í•œ í‚¤ì›Œë“œ ì œê±°
        for keyword in self.unwanted_keywords:
            cleaned = cleaned.replace(keyword, '')
        
        # ë‹¤ì¤‘ ê³µë°± ì •ë¦¬
        cleaned = re.sub(r'\s+', ' ', cleaned).strip()
        
        # ë§ˆì§€ë§‰ì— ë‚¨ëŠ” íŠ¹ìˆ˜ë¬¸ì ì œê±°
        cleaned = re.sub(r'[\+\-]+$', '', cleaned).strip()
        
        return cleaned
    
    def extract_brand_and_name(self, product_name: str) -> Tuple[str, str]:
        """
        ë¸Œëœë“œëª…ê³¼ ì œí’ˆëª… ì¶”ì¶œ
        
        Args:
            product_name: ì œí’ˆëª… (ì •ì œ ì „ ë˜ëŠ” í›„)
            
        Returns:
            (ë¸Œëœë“œëª…, ì œí’ˆëª…)
        """
        cleaned = self.clean_product_name(product_name)
        
        # ì²« ë²ˆì§¸ ë‹¨ì–´ë¥¼ ë¸Œëœë“œë¡œ ì¶”ì • (ê³µë°± ê¸°ì¤€)
        parts = cleaned.split()
        if len(parts) > 0:
            brand = parts[0]
            name = ' '.join(parts[1:]) if len(parts) > 1 else parts[0]
        else:
            brand = 'Unknown'
            name = cleaned
        
        return brand, name
    
    def check_if_package_product(self, product_name: str, ingredients: List[str]) -> bool:
        """
        ê¸°íš ìƒí’ˆì¸ì§€ í™•ì¸ (í•œ ì œí’ˆì— ì—¬ëŸ¬ ì•„ì´í…œì´ í¬í•¨ëœ ê²½ìš°)
        
        Args:
            product_name: ì œí’ˆëª…
            ingredients: ì„±ë¶„ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ê¸°íš ìƒí’ˆ ì—¬ë¶€
        """
        # ì œí’ˆëª…ì— ê¸°íš ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
        package_keywords = ['ë”ë¸”', 'íŠ¸ë¦¬í”Œ', '2ê°œì…', '3ê°œì…', 'ì„¸íŠ¸']
        for keyword in package_keywords:
            if keyword in product_name:
                return True
        
        # ì„±ë¶„ ìˆ˜ê°€ ë¹„ì •ìƒì ìœ¼ë¡œ ë§ì€ ê²½ìš° (ìƒ˜í”Œë§ í•„ìš”)
        if len(ingredients) > 50:
            return True
        
        return False
    
    def split_package_product(self, product_name: str, ingredients: List[str]) -> List[Dict]:
        """
        ê¸°íš ìƒí’ˆì„ ê°œë³„ ì œí’ˆìœ¼ë¡œ ë¶„ë¦¬
        
        Args:
            product_name: ì œí’ˆëª…
            ingredients: ì„±ë¶„ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ë¶„ë¦¬ëœ ì œí’ˆ ë¦¬ìŠ¤íŠ¸
        """
        # TODO: ë³µì¡í•œ ê¸°íš ìƒí’ˆ ë¶„ë¦¬ ë¡œì§ êµ¬í˜„
        # í˜„ì¬ëŠ” ì›ë³¸ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ìˆ˜ë™ ê²€í†  í•„ìš”)
        
        brand, name = self.extract_brand_and_name(product_name)
        
        return [{
            'brand': brand,
            'product_name': name,
            'original_name': product_name,
            'is_package': True,
            'ingredients': ingredients,
            'note': 'ê¸°íš ìƒí’ˆ - ìˆ˜ë™ ê²€í†  í•„ìš”'
        }]
    
    def categorize_ingredients(self, ingredients: List[str]) -> Dict[str, List[str]]:
        """
        ì„±ë¶„ì„ í™•ì¸ëœ ì„±ë¶„ê³¼ ë¯¸í™•ì¸ ì„±ë¶„ìœ¼ë¡œ ë¶„ë¥˜
        
        Args:
            ingredients: ì„±ë¶„ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            {'confirmed': [...], 'unconfirmed': [...]}
        """
        confirmed = []
        unconfirmed = []
        
        for ing in ingredients:
            ing_clean = ing.strip()
            
            # ë¹ˆ ë¬¸ìì—´ì´ë‚˜ ìˆ«ìë§Œ ìˆëŠ” ê²½ìš° ì œì™¸
            if not ing_clean or ing_clean.isdigit():
                continue
            
            # ì „ì²´ ì„±ë¶„ ë°ì´í„°ì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            if ing_clean in self.all_ingredients:
                confirmed.append(ing_clean)
            else:
                # ìœ ì‚¬ë„ ê²€ì‚¬ (ì¶”í›„ êµ¬í˜„)
                unconfirmed.append(ing_clean)
        
        return {
            'confirmed': confirmed,
            'unconfirmed': unconfirmed
        }
    
    def process_json_file(self, file_path: str, category: str) -> pd.DataFrame:
        """
        JSON íŒŒì¼ì—ì„œ ì œí’ˆ ë°ì´í„° ì¶”ì¶œ ë° ì •ì œ
        
        Args:
            file_path: JSON íŒŒì¼ ê²½ë¡œ
            category: ì œí’ˆ ì¹´í…Œê³ ë¦¬
            
        Returns:
            ì •ì œëœ ë°ì´í„° DataFrame
        """
        print(f"\nğŸ“‚ íŒŒì¼ ì²˜ë¦¬ ì¤‘: {file_path}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"   ì›ë³¸ ë°ì´í„°: {len(data)}ê°œ ì œí’ˆ")
        
        processed_products = []
        
        for item in data:
            product_name = item.get('ì œí’ˆëª…', '')
            url = item.get('URL', '')
            ingredients = item.get('ì„±ë¶„ë¦¬ìŠ¤íŠ¸', [])
            
            # ì œí’ˆëª… ì •ì œ
            cleaned_name = self.clean_product_name(product_name)
            brand, name = self.extract_brand_and_name(cleaned_name)
            
            # ê¸°íš ìƒí’ˆ ì—¬ë¶€ í™•ì¸
            is_package = self.check_if_package_product(product_name, ingredients)
            
            # ì„±ë¶„ ë¶„ë¥˜
            categorized = self.categorize_ingredients(ingredients)
            
            # ì œí’ˆ ë°ì´í„° ìƒì„±
            product_data = {
                'category': category,
                'brand': brand,
                'product_name': name,
                'original_name': product_name,
                'url': url,
                'is_package': is_package,
                'total_ingredients': len(ingredients),
                'confirmed_ingredients_count': len(categorized['confirmed']),
                'unconfirmed_ingredients_count': len(categorized['unconfirmed']),
                'confirmed_ingredients': ','.join(categorized['confirmed']),
                'unconfirmed_ingredients': ','.join(categorized['unconfirmed']),
                'all_ingredients': ','.join(ingredients),
            }
            
            processed_products.append(product_data)
            
            # ê¸°íš ìƒí’ˆì¸ ê²½ìš° ë³„ë„ ì²˜ë¦¬
            if is_package:
                package_products = self.split_package_product(product_name, ingredients)
                for pkg_product in package_products:
                    # ì¶”ê°€ ê²€í† ìš© ë°ì´í„° ì €ì¥
                    pass
        
        df = pd.DataFrame(processed_products)
        print(f"   ì²˜ë¦¬ ì™„ë£Œ: {len(df)}ê°œ ì œí’ˆ")
        
        return df
    
    def process_all_files(self, output_file: str = 'data/processed/oliveyoung_products_cleaned.csv'):
        """
        ëª¨ë“  ì˜¬ë¦¬ë¸Œì˜ JSON íŒŒì¼ ì²˜ë¦¬
        
        Args:
            output_file: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        print("=" * 60)
        print("ğŸ§´ ì˜¬ë¦¬ë¸Œì˜ ì œí’ˆ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")
        print("=" * 60)
        
        # 1. ì „ì²´ ì„±ë¶„ ë°ì´í„° ë¡œë“œ
        self.load_public_api_ingredients()
        
        # 2. JSON íŒŒì¼ ëª©ë¡
        json_files = [
            ('data/raw/oliveyoung_ìŠ¤í‚¨_í† ë„ˆ_raw_limited.json', 'ìŠ¤í‚¨_í† ë„ˆ'),
            ('data/raw/oliveyoung_ì—ì„¼ìŠ¤_ì„¸ëŸ¼_ì•°í”Œ_raw_limited.json', 'ì—ì„¼ìŠ¤_ì„¸ëŸ¼_ì•°í”Œ'),
            ('data/raw/oliveyoung_í¬ë¦¼_raw_limited.json', 'í¬ë¦¼'),
            ('data/raw/oliveyoung_ë¡œì…˜_raw_limited.json', 'ë¡œì…˜'),
            ('data/raw/oliveyoung_ë¯¸ìŠ¤íŠ¸_ì˜¤ì¼_raw_limited.json', 'ë¯¸ìŠ¤íŠ¸_ì˜¤ì¼'),
        ]
        
        # 3. ê° íŒŒì¼ ì²˜ë¦¬
        all_dataframes = []
        
        for file_path, category in json_files:
            if Path(file_path).exists():
                df = self.process_json_file(file_path, category)
                all_dataframes.append(df)
            else:
                print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {file_path}")
        
        # 4. ëª¨ë“  ë°ì´í„° í†µí•©
        if all_dataframes:
            combined_df = pd.concat(all_dataframes, ignore_index=True)
            
            # 5. í†µê³„ ì¶œë ¥
            print("\n" + "=" * 60)
            print("ğŸ“Š ì „ì²˜ë¦¬ ê²°ê³¼ í†µê³„")
            print("=" * 60)
            print(f"ì´ ì œí’ˆ ìˆ˜: {len(combined_df)}")
            print(f"\nì¹´í…Œê³ ë¦¬ë³„:")
            print(combined_df['category'].value_counts())
            print(f"\nê¸°íš ìƒí’ˆ ìˆ˜: {combined_df['is_package'].sum()}ê°œ")
            print(f"\nì„±ë¶„ ë§¤ì¹­ë¥ :")
            print(f"  - ì „ì²´ ì„±ë¶„: {combined_df['total_ingredients'].sum():,}")
            print(f"  - í™•ì¸ëœ ì„±ë¶„: {combined_df['confirmed_ingredients_count'].sum():,}")
            print(f"  - ë¯¸í™•ì¸ ì„±ë¶„: {combined_df['unconfirmed_ingredients_count'].sum():,}")
            match_rate = (combined_df['confirmed_ingredients_count'].sum() / 
                         combined_df['total_ingredients'].sum() * 100) if combined_df['total_ingredients'].sum() > 0 else 0
            print(f"  - ë§¤ì¹­ë¥ : {match_rate:.1f}%")
            
            # 6. CSV ì €ì¥
            Path(output_file).parent.mkdir(parents=True, exist_ok=True)
            combined_df.to_csv(output_file, index=False, encoding='utf-8-sig')
            print(f"\nâœ… ì €ì¥ ì™„ë£Œ: {output_file}")
            
            # 7. ë¯¸í™•ì¸ ì„±ë¶„ ë³„ë„ ì €ì¥
            unconfirmed_file = output_file.replace('.csv', '_unconfirmed.csv')
            unconfirmed_df = combined_df[combined_df['unconfirmed_ingredients_count'] > 0].copy()
            if len(unconfirmed_df) > 0:
                unconfirmed_df.to_csv(unconfirmed_file, index=False, encoding='utf-8-sig')
                print(f"âœ… ë¯¸í™•ì¸ ì„±ë¶„ ì €ì¥: {unconfirmed_file}")
            
            # 8. ê¸°íš ìƒí’ˆ ë³„ë„ ì €ì¥
            package_file = output_file.replace('.csv', '_packages.csv')
            package_df = combined_df[combined_df['is_package'] == True].copy()
            if len(package_df) > 0:
                package_df.to_csv(package_file, index=False, encoding='utf-8-sig')
                print(f"âœ… ê¸°íš ìƒí’ˆ ì €ì¥: {package_file}")
            
            print("\n" + "=" * 60)
            print("ğŸ‰ ì „ì²˜ë¦¬ ì™„ë£Œ!")
            print("=" * 60)
            
            return combined_df
        else:
            print("âŒ ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    preprocessor = OliveYoungDataPreprocessor()
    result = preprocessor.process_all_files()
    
    if result is not None:
        print("\nğŸ“ ë‹¤ìŒ ë‹¨ê³„:")
        print("1. ë¯¸í™•ì¸ ì„±ë¶„ íŒŒì¼ì„ í™•ì¸í•˜ì—¬ ìˆ˜ë™ìœ¼ë¡œ ì •ë¦¬")
        print("2. ê¸°íš ìƒí’ˆ íŒŒì¼ì„ í™•ì¸í•˜ì—¬ ìˆ˜ë™ìœ¼ë¡œ ë¶„ë¦¬")
        print("3. ì „ì²´ ì„±ë¶„ ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸")


if __name__ == "__main__":
    main()
