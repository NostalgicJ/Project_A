#!/usr/bin/env python3
"""
ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
ì‹¤ì œ í™”ì¥í’ˆ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì—¬ ìœ„í—˜í•œ ì„±ë¶„ ì¡°í•©ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸
"""
import sys
import os
sys.path.append('src')

import pandas as pd
import numpy as np
from models.advanced_ingredient_analyzer import AdvancedCosmeticAnalyzer
import pickle

def load_real_data():
    """ì‹¤ì œ í™”ì¥í’ˆ ë°ì´í„° ë¡œë“œ"""
    print("ğŸ“Š ì‹¤ì œ í™”ì¥í’ˆ ë°ì´í„° ë¡œë“œ ì¤‘...")
    
    try:
        # ì œí’ˆ ë°ì´í„° ë¡œë“œ
        products_df = pd.read_csv('data/processed_cosmetics_final_2.csv')
        print(f"âœ… ì œí’ˆ ë°ì´í„°: {len(products_df)}ê°œ")
        
        # ì„±ë¶„ ë°ì´í„° ë¡œë“œ
        ingredients_df = pd.read_csv('data/integrated_product_ingredient_normalized_2.csv')
        print(f"âœ… ì„±ë¶„ ë°ì´í„°: {len(ingredients_df)}ê°œ")
        
        # ë§ˆìŠ¤í„° ì„±ë¶„ ë¡œë“œ
        master_ingredients = pd.read_csv('data/coos_master_ingredients_cleaned.csv')
        print(f"âœ… ë§ˆìŠ¤í„° ì„±ë¶„: {len(master_ingredients)}ê°œ")
        
        return products_df, ingredients_df, master_ingredients
        
    except FileNotFoundError as e:
        print(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        return None, None, None

def create_ingredient_vocab(products_df, master_ingredients):
    """ì„±ë¶„ ì–´íœ˜ ì‚¬ì „ ìƒì„±"""
    print("ğŸ”¤ ì„±ë¶„ ì–´íœ˜ ì‚¬ì „ ìƒì„± ì¤‘...")
    
    all_ingredients = set()
    
    # ì œí’ˆ ë°ì´í„°ì—ì„œ ì„±ë¶„ ì¶”ì¶œ
    for idx, row in products_df.iterrows():
        if pd.notna(row['ì„±ë¶„_ë¬¸ìì—´']):
            ingredients = [ing.strip() for ing in str(row['ì„±ë¶„_ë¬¸ìì—´']).split(',')]
            all_ingredients.update(ingredients)
    
    # ë§ˆìŠ¤í„° ì„±ë¶„ì—ì„œ ì¶”ì¶œ
    for idx, row in master_ingredients.iterrows():
        if pd.notna(row['ì›ë£Œëª…_ì •ì œë¨']):
            all_ingredients.add(str(row['ì›ë£Œëª…_ì •ì œë¨']).strip())
    
    # ìƒìœ„ 1000ê°œ ì„±ë¶„ë§Œ ì‚¬ìš© (ë©”ëª¨ë¦¬ ì ˆì•½)
    ingredient_counts = {}
    for ingredient in all_ingredients:
        if len(ingredient) > 2:  # ë„ˆë¬´ ì§§ì€ ì„±ë¶„ ì œì™¸
            ingredient_counts[ingredient] = ingredient_counts.get(ingredient, 0) + 1
    
    # ë¹ˆë„ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ 1000ê°œ ì„ íƒ
    sorted_ingredients = sorted(ingredient_counts.items(), key=lambda x: x[1], reverse=True)
    top_ingredients = [ing[0] for ing in sorted_ingredients[:1000]]
    
    print(f"âœ… ì„±ë¶„ ì–´íœ˜ ì‚¬ì „ ìƒì„± ì™„ë£Œ: {len(top_ingredients)}ê°œ")
    return top_ingredients

def create_training_data_from_real_data(products_df, vocab):
    """ì‹¤ì œ ë°ì´í„°ì—ì„œ í•™ìŠµ ë°ì´í„° ìƒì„±"""
    print("ğŸ“š ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ í•™ìŠµ ë°ì´í„° ìƒì„± ì¤‘...")
    
    # ì œí’ˆë³„ ì„±ë¶„ ì¡°í•© ìƒì„±
    product_ingredients = {}
    for idx, row in products_df.iterrows():
        # ì„±ë¶„_ë¬¸ìì—´ ì»¬ëŸ¼ í™•ì¸
        if 'ì„±ë¶„_ë¬¸ìì—´' in row and pd.notna(row['ì„±ë¶„_ë¬¸ìì—´']):
            ingredients = [ing.strip() for ing in str(row['ì„±ë¶„_ë¬¸ìì—´']).split(',')]
            # ì–´íœ˜ì— ìˆëŠ” ì„±ë¶„ë§Œ í•„í„°ë§
            filtered_ingredients = [ing for ing in ingredients if ing in vocab]
            if len(filtered_ingredients) > 1:
                product_ingredients[f"{row.get('ë¸Œëœë“œëª…_ì •ë¦¬', 'Unknown')}_{row.get('ì œí’ˆëª…_ì •ë¦¬', 'Unknown')}"] = filtered_ingredients
    
    print(f"âœ… ì œí’ˆë³„ ì„±ë¶„ ë°ì´í„°: {len(product_ingredients)}ê°œ")
    
    # ë§Œì•½ ì‹¤ì œ ë°ì´í„°ê°€ ì—†ë‹¤ë©´ ê°€ìƒ ë°ì´í„° ìƒì„±
    if len(product_ingredients) == 0:
        print("âš ï¸ ì‹¤ì œ ë°ì´í„°ì—ì„œ ì„±ë¶„ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê°€ìƒ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        
        # ì£¼ìš” ì„±ë¶„ë“¤ë¡œ ê°€ìƒ ì œí’ˆ ìƒì„±
        main_ingredients = ['ë¹„íƒ€ë¯¼C', 'ë ˆí‹°ë†€', 'íˆì•Œë£¨ë¡ ì‚°', 'ì„¸ë¼ë§ˆì´ë“œ', 'ë‚˜ì´ì•„ì‹ ì•„ë§ˆì´ë“œ', 
                           'AHA', 'BHA', 'íŒí…Œë†€', 'ì•„ì—°', 'ë‹ˆì•„ì‹ ì•„ë§ˆì´ë“œ']
        
        # ê°€ìƒ ì œí’ˆë“¤ ìƒì„±
        virtual_products = {
            'ì œí’ˆ1': ['ë¹„íƒ€ë¯¼C', 'íˆì•Œë£¨ë¡ ì‚°', 'íŒí…Œë†€'],
            'ì œí’ˆ2': ['ë ˆí‹°ë†€', 'ì„¸ë¼ë§ˆì´ë“œ', 'ë‚˜ì´ì•„ì‹ ì•„ë§ˆì´ë“œ'],
            'ì œí’ˆ3': ['ë¹„íƒ€ë¯¼C', 'ë ˆí‹°ë†€', 'AHA'],  # ìœ„í—˜í•œ ì¡°í•©
            'ì œí’ˆ4': ['íˆì•Œë£¨ë¡ ì‚°', 'ì„¸ë¼ë§ˆì´ë“œ', 'íŒí…Œë†€'],  # ì‹œë„ˆì§€ ì¡°í•©
            'ì œí’ˆ5': ['BHA', 'ë ˆí‹°ë†€', 'ì•„ì—°'],  # ìœ„í—˜í•œ ì¡°í•©
            'ì œí’ˆ6': ['ë¹„íƒ€ë¯¼C', 'ë¹„íƒ€ë¯¼E', 'íˆì•Œë£¨ë¡ ì‚°'],  # ì‹œë„ˆì§€ ì¡°í•©
        }
        
        product_ingredients = virtual_products
    
    # ì„±ë¶„ ì¡°í•© ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ìƒì„±
    ingredient_pairs = []
    labels = []
    
    # ì‹¤ì œ ì œí’ˆì—ì„œ ì„±ë¶„ ì¡°í•© ì¶”ì¶œ
    for product_id, ingredients in product_ingredients.items():
        for i, ing1 in enumerate(ingredients):
            for ing2 in ingredients[i+1:]:
                ingredient_pairs.append((ing1, ing2))
                
                # ë¼ë²¨ ê²°ì • (ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜)
                if any(keyword in ing1.lower() for keyword in ['ë¹„íƒ€ë¯¼c', 'ascorbic', 'ë ˆí‹°ë†€', 'retinol']):
                    if any(keyword in ing2.lower() for keyword in ['ë¹„íƒ€ë¯¼c', 'ascorbic', 'ë ˆí‹°ë†€', 'retinol']):
                        labels.append(2)  # ìœ„í—˜
                    else:
                        labels.append(1)  # ì£¼ì˜
                elif any(keyword in ing2.lower() for keyword in ['ë¹„íƒ€ë¯¼c', 'ascorbic', 'ë ˆí‹°ë†€', 'retinol']):
                    labels.append(1)  # ì£¼ì˜
                else:
                    labels.append(0)  # ì•ˆì „
    
    print(f"âœ… í•™ìŠµ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(ingredient_pairs)}ê°œ ì¡°í•©")
    return ingredient_pairs, labels

def train_model():
    """ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨"""
    print("ğŸš€ í™”ì¥í’ˆ ì„±ë¶„ ì¡°í•© ë¶„ì„ ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
    print("=" * 60)
    
    # 1. ë°ì´í„° ë¡œë“œ
    products_df, ingredients_df, master_ingredients = load_real_data()
    if products_df is None:
        print("âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        return
    
    # 2. ì„±ë¶„ ì–´íœ˜ ì‚¬ì „ ìƒì„±
    vocab = create_ingredient_vocab(products_df, master_ingredients)
    
    # 3. ê³ ê¸‰ ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = AdvancedCosmeticAnalyzer()
    
    # 4. ì‹¤ì œ ë°ì´í„°ë¡œ í•™ìŠµ ë°ì´í„° ìƒì„±
    ingredient_pairs, labels = create_training_data_from_real_data(products_df, vocab)
    
    # 5. ëª¨ë¸ í›ˆë ¨ (ì–´íœ˜ ì‚¬ì „ê³¼ í•™ìŠµ ë°ì´í„°ë¥¼ ì§ì ‘ ì „ë‹¬)
    print("\nğŸ§  ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨ ì¤‘...")
    model = analyzer.train_model_with_data(vocab, ingredient_pairs, labels, num_epochs=30)
    
    # 6. ëª¨ë¸ ì €ì¥
    model_path = "models/advanced_ingredient_analyzer.pth"
    os.makedirs("models", exist_ok=True)
    analyzer.save_model(model_path)
    
    # 7. í…ŒìŠ¤íŠ¸
    print("\nğŸ§ª ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    test_cases = [
        ['ë¹„íƒ€ë¯¼C', 'ë ˆí‹°ë†€', 'íˆì•Œë£¨ë¡ ì‚°'],
        ['ë¹„íƒ€ë¯¼C', 'ë¹„íƒ€ë¯¼E', 'íˆì•Œë£¨ë¡ ì‚°'],
        ['íˆì•Œë£¨ë¡ ì‚°', 'ì„¸ë¼ë§ˆì´ë“œ', 'íŒí…Œë†€']
    ]
    
    for i, test_ingredients in enumerate(test_cases, 1):
        print(f"\ní…ŒìŠ¤íŠ¸ {i}: {test_ingredients}")
        result = analyzer.analyze_combination(test_ingredients)
        print(f"  ë¶„ë¥˜: {result['predicted_class']}")
        print(f"  ìœ„í—˜ë„: {result['danger_score']:.1%}")
        print(f"  ì‹œë„ˆì§€: {result['synergy_score']:.1%}")
        print(f"  ë¶„ì„: {result['analysis']}")
    
    print("\nğŸ‰ ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
    print("ì´ì œ ì‹¤ì œ ë°ì´í„°ë¥¼ í•™ìŠµí•œ ëª¨ë¸ì´ ìœ„í—˜í•œ ì„±ë¶„ ì¡°í•©ì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    train_model()
