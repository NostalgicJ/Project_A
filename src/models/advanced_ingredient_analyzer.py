"""
ê³ ê¸‰ í™”ì¥í’ˆ ì„±ë¶„ ì¡°í•© ë¶„ì„ ë”¥ëŸ¬ë‹ ëª¨ë¸
ì‹¤ì œ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì—¬ ìœ„í—˜í•œ ì¡°í•©ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
from typing import List, Dict, Tuple, Optional
import pickle
import os
from sklearn.metrics import accuracy_score, classification_report
from torch.utils.data import Dataset, DataLoader
import warnings
warnings.filterwarnings('ignore')


class IngredientInteractionDataset(Dataset):
    """ì„±ë¶„ ìƒí˜¸ì‘ìš© ë°ì´í„°ì…‹"""
    
    def __init__(self, ingredient_pairs, labels, vocab_to_idx):
        self.ingredient_pairs = ingredient_pairs
        self.labels = labels
        self.vocab_to_idx = vocab_to_idx
        
    def __len__(self):
        return len(self.ingredient_pairs)
    
    def __getitem__(self, idx):
        pair = self.ingredient_pairs[idx]
        label = self.labels[idx]
        
        # ì„±ë¶„ì„ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
        ing1_idx = self.vocab_to_idx.get(pair[0], 0)
        ing2_idx = self.vocab_to_idx.get(pair[1], 0)
        
        return {
            'ingredient1': torch.tensor(ing1_idx, dtype=torch.long),
            'ingredient2': torch.tensor(ing2_idx, dtype=torch.long),
            'label': torch.tensor(label, dtype=torch.long)
        }


class IngredientInteractionModel(nn.Module):
    """ì„±ë¶„ ìƒí˜¸ì‘ìš© ë¶„ì„ ë”¥ëŸ¬ë‹ ëª¨ë¸"""
    
    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=256):
        super().__init__()
        
        # ì„±ë¶„ ì„ë² ë”©
        self.ingredient_embedding = nn.Embedding(vocab_size, embedding_dim)
        
        # ì„±ë¶„ ê°„ ìƒí˜¸ì‘ìš© ë¶„ì„ì„ ìœ„í•œ ë„¤íŠ¸ì›Œí¬
        self.interaction_net = nn.Sequential(
            nn.Linear(embedding_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim // 2, hidden_dim // 4),
            nn.ReLU(),
            nn.Dropout(0.2)
        )
        
        # ë¶„ë¥˜ í—¤ë“œ (0: ì•ˆì „, 1: ì£¼ì˜, 2: ìœ„í—˜)
        self.classifier = nn.Linear(hidden_dim // 4, 3)
        
        # ìœ„í—˜ë„ ì ìˆ˜ í—¤ë“œ (0-1)
        self.danger_score = nn.Sequential(
            nn.Linear(hidden_dim // 4, 1),
            nn.Sigmoid()
        )
        
        # ì‹œë„ˆì§€ ì ìˆ˜ í—¤ë“œ (0-1)
        self.synergy_score = nn.Sequential(
            nn.Linear(hidden_dim // 4, 1),
            nn.Sigmoid()
        )
        
    def forward(self, ingredient1, ingredient2):
        # ì„±ë¶„ ì„ë² ë”©
        emb1 = self.ingredient_embedding(ingredient1)
        emb2 = self.ingredient_embedding(ingredient2)
        
        # ì„±ë¶„ ì¡°í•© ë²¡í„°
        combined = torch.cat([emb1, emb2], dim=-1)
        
        # ìƒí˜¸ì‘ìš© ë¶„ì„
        interaction = self.interaction_net(combined)
        
        # ë¶„ë¥˜ ë° ì ìˆ˜
        classification = self.classifier(interaction)
        danger_score = self.danger_score(interaction)
        synergy_score = self.synergy_score(interaction)
        
        return {
            'classification': classification,
            'danger_score': danger_score,
            'synergy_score': synergy_score
        }


class AdvancedCosmeticAnalyzer:
    """ê³ ê¸‰ í™”ì¥í’ˆ ì„±ë¶„ ë¶„ì„ê¸° (ë”¥ëŸ¬ë‹ ê¸°ë°˜)"""
    
    def __init__(self, model_path=None):
        self.model = None
        self.vocab = None
        self.vocab_to_idx = None
        self.idx_to_vocab = None
        self.model_path = model_path
        
        # ì•Œë ¤ì§„ ìœ„í—˜í•œ ì¡°í•© (í•™ìŠµ ë°ì´í„°)
        self.known_dangerous_combinations = {
            ('ë¹„íƒ€ë¯¼C', 'ë ˆí‹°ë†€'): {'danger': 0.9, 'reason': 'pH ë¶ˆì¼ì¹˜ë¡œ íš¨ê³¼ ìƒì‡„'},
            ('AHA', 'ë ˆí‹°ë†€'): {'danger': 0.8, 'reason': 'ê³¼ë„í•œ ê°ì§ˆ ì œê±°'},
            ('BHA', 'ë ˆí‹°ë†€'): {'danger': 0.8, 'reason': 'ê³¼ë„í•œ ê°ì§ˆ ì œê±°'},
            ('ë‹ˆì•„ì‹ ì•„ë§ˆì´ë“œ', 'ë¹„íƒ€ë¯¼C'): {'danger': 0.7, 'reason': 'pH ë¶ˆì¼ì¹˜'},
            ('ë²¤ì¡°ì¼í¼ì˜¥ì‚¬ì´ë“œ', 'ë ˆí‹°ë†€'): {'danger': 0.9, 'reason': 'ê³¼ë„í•œ ê°ì§ˆ ì œê±°'},
            ('í•˜ì´ë“œë¡œí€´ë…¼', 'ë ˆí‹°ë†€'): {'danger': 0.6, 'reason': 'í”¼ë¶€ ìê·¹ ìœ„í—˜'},
            ('ì‚´ë¦¬ì‹¤ë¦­ì• ì”¨ë“œ', 'ë ˆí‹°ë†€'): {'danger': 0.7, 'reason': 'ê³¼ë„í•œ ê°ì§ˆ ì œê±°'},
        }
        
        # ì•Œë ¤ì§„ ì‹œë„ˆì§€ ì¡°í•©
        self.known_synergy_combinations = {
            ('ë¹„íƒ€ë¯¼C', 'ë¹„íƒ€ë¯¼E'): {'synergy': 0.8, 'reason': 'í•­ì‚°í™” íš¨ê³¼ ì¦ëŒ€'},
            ('íˆì•Œë£¨ë¡ ì‚°', 'ì„¸ë¼ë§ˆì´ë“œ'): {'synergy': 0.7, 'reason': 'ë³´ìŠµ íš¨ê³¼ ì¦ëŒ€'},
            ('ë‚˜ì´ì•„ì‹ ì•„ë§ˆì´ë“œ', 'ì•„ì—°'): {'synergy': 0.6, 'reason': 'ëª¨ê³µ ê´€ë¦¬ íš¨ê³¼ ì¦ëŒ€'},
            ('ë ˆí‹°ë†€', 'í•˜ì´ë“œë¡œí€´ë…¼'): {'synergy': 0.5, 'reason': 'ë¯¸ë°± íš¨ê³¼ ì¦ëŒ€'},
            ('í©íƒ€ì´ë“œ', 'ë ˆí‹°ë†€'): {'synergy': 0.6, 'reason': 'ì£¼ë¦„ ê°œì„  íš¨ê³¼ ì¦ëŒ€'},
        }
    
    def create_training_data(self, vocab):
        """í•™ìŠµ ë°ì´í„° ìƒì„±"""
        print("ğŸ“Š í•™ìŠµ ë°ì´í„° ìƒì„± ì¤‘...")
        
        # ì„±ë¶„ ìŒê³¼ ë¼ë²¨ ìƒì„±
        ingredient_pairs = []
        labels = []
        
        # ìœ„í—˜í•œ ì¡°í•© (ë¼ë²¨: 2)
        for (ing1, ing2), info in self.known_dangerous_combinations.items():
            if ing1 in vocab and ing2 in vocab:
                ingredient_pairs.append((ing1, ing2))
                labels.append(2)  # ìœ„í—˜
        
        # ì‹œë„ˆì§€ ì¡°í•© (ë¼ë²¨: 0)
        for (ing1, ing2), info in self.known_synergy_combinations.items():
            if ing1 in vocab and ing2 in vocab:
                ingredient_pairs.append((ing1, ing2))
                labels.append(0)  # ì•ˆì „
        
        # ëœë¤ ì¡°í•© (ë¼ë²¨: 1 - ì£¼ì˜)
        import random
        random.seed(42)
        for _ in range(len(ingredient_pairs)):
            ing1 = random.choice(vocab)
            ing2 = random.choice(vocab)
            if ing1 != ing2 and (ing1, ing2) not in self.known_dangerous_combinations:
                ingredient_pairs.append((ing1, ing2))
                labels.append(1)  # ì£¼ì˜
        
        print(f"âœ… í•™ìŠµ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(ingredient_pairs)}ê°œ ì¡°í•©")
        return ingredient_pairs, labels
    
    def train_model(self, vocab, num_epochs=50):
        """ëª¨ë¸ í›ˆë ¨"""
        print("ğŸ§  ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        
        # ì–´íœ˜ ì‚¬ì „ ì„¤ì •
        self.vocab = vocab
        self.vocab_to_idx = {ing: idx for idx, ing in enumerate(vocab)}
        self.idx_to_vocab = {idx: ing for ing, idx in self.vocab_to_idx.items()}
        
        # í•™ìŠµ ë°ì´í„° ìƒì„±
        ingredient_pairs, labels = self.create_training_data(vocab)
        
        # ë°ì´í„°ì…‹ ìƒì„±
        dataset = IngredientInteractionDataset(ingredient_pairs, labels, self.vocab_to_idx)
        dataloader = DataLoader(dataset, batch_size=32, shuffle=True)
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.model = IngredientInteractionModel(len(vocab))
        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)
        criterion = nn.CrossEntropyLoss()
        
        # í›ˆë ¨
        self.model.train()
        for epoch in range(num_epochs):
            total_loss = 0
            for batch in dataloader:
                ingredient1 = batch['ingredient1']
                ingredient2 = batch['ingredient2']
                labels = batch['label']
                
                # ìˆœì „íŒŒ
                outputs = self.model(ingredient1, ingredient2)
                loss = criterion(outputs['classification'], labels)
                
                # ì—­ì „íŒŒ
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                
                total_loss += loss.item()
            
            if epoch % 10 == 0:
                print(f"Epoch {epoch}: Loss = {total_loss/len(dataloader):.4f}")
        
        print("âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
        return self.model
    
    def train_model_with_data(self, vocab, ingredient_pairs, labels, num_epochs=50):
        """ì™¸ë¶€ ë°ì´í„°ë¡œ ëª¨ë¸ í›ˆë ¨"""
        print("ğŸ§  ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        
        # ì–´íœ˜ ì‚¬ì „ ì„¤ì •
        self.vocab = vocab
        self.vocab_to_idx = {ing: idx for idx, ing in enumerate(vocab)}
        self.idx_to_vocab = {idx: ing for ing, idx in self.vocab_to_idx.items()}
        
        print(f"ğŸ“Š í•™ìŠµ ë°ì´í„°: {len(ingredient_pairs)}ê°œ ì¡°í•©")
        
        # ë°ì´í„°ì…‹ ìƒì„±
        dataset = IngredientInteractionDataset(ingredient_pairs, labels, self.vocab_to_idx)
        dataloader = DataLoader(dataset, batch_size=min(32, len(ingredient_pairs)), shuffle=True)
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.model = IngredientInteractionModel(len(vocab))
        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)
        criterion = nn.CrossEntropyLoss()
        
        # í›ˆë ¨
        self.model.train()
        for epoch in range(num_epochs):
            total_loss = 0
            for batch in dataloader:
                ingredient1 = batch['ingredient1']
                ingredient2 = batch['ingredient2']
                labels = batch['label']
                
                # ìˆœì „íŒŒ
                outputs = self.model(ingredient1, ingredient2)
                loss = criterion(outputs['classification'], labels)
                
                # ì—­ì „íŒŒ
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                
                total_loss += loss.item()
            
            if epoch % 10 == 0:
                print(f"Epoch {epoch}: Loss = {total_loss/len(dataloader):.4f}")
        
        print("âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
        return self.model
    
    def analyze_combination(self, ingredients):
        """ì„±ë¶„ ì¡°í•© ë¶„ì„ (ë”¥ëŸ¬ë‹ ê¸°ë°˜)"""
        if self.model is None:
            return self._rule_based_analysis(ingredients)
        
        self.model.eval()
        
        # ëª¨ë“  ì„±ë¶„ ìŒì— ëŒ€í•´ ë¶„ì„
        danger_scores = []
        synergy_scores = []
        classifications = []
        
        with torch.no_grad():
            for i, ing1 in enumerate(ingredients):
                for ing2 in ingredients[i+1:]:
                    # ì„±ë¶„ì„ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
                    ing1_idx = self.vocab_to_idx.get(ing1, 0)
                    ing2_idx = self.vocab_to_idx.get(ing2, 0)
                    
                    # ëª¨ë¸ ì˜ˆì¸¡
                    outputs = self.model(
                        torch.tensor([ing1_idx], dtype=torch.long),
                        torch.tensor([ing2_idx], dtype=torch.long)
                    )
                    
                    classification = torch.softmax(outputs['classification'], dim=1)
                    predicted_class = torch.argmax(classification, dim=1).item()
                    danger_score = outputs['danger_score'].item()
                    synergy_score = outputs['synergy_score'].item()
                    
                    classifications.append(predicted_class)
                    danger_scores.append(danger_score)
                    synergy_scores.append(synergy_score)
        
        # ì „ì²´ ì¡°í•© ë¶„ì„
        if danger_scores:
            max_danger = max(danger_scores)
            avg_synergy = np.mean(synergy_scores)
            most_dangerous_class = max(set(classifications), key=classifications.count)
        else:
            max_danger = 0.0
            avg_synergy = 0.0
            most_dangerous_class = 0
        
        # ë¶„ë¥˜ ê²°ì •
        if max_danger > 0.7:
            predicted_class = 'ìœ„í—˜'
            confidence = max_danger
        elif max_danger > 0.4:
            predicted_class = 'ì£¼ì˜'
            confidence = max_danger
        else:
            predicted_class = 'ì•ˆì „'
            confidence = 1 - max_danger
        
        # ë¶„ì„ í…ìŠ¤íŠ¸ ìƒì„±
        if predicted_class == 'ìœ„í—˜':
            analysis = f"âš ï¸ ì£¼ì˜: ì´ ì„±ë¶„ ì¡°í•©ì€ ìœ„í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ìœ„í—˜ë„: {max_danger:.1%})"
        elif predicted_class == 'ì£¼ì˜':
            analysis = f"âš ï¸ ì£¼ì˜: ì´ ì„±ë¶„ ì¡°í•©ì€ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤. (ìœ„í—˜ë„: {max_danger:.1%})"
        else:
            analysis = f"âœ… ì•ˆì „: ì´ ì„±ë¶„ ì¡°í•©ì€ ì•ˆì „í•©ë‹ˆë‹¤."
        
        return {
            'predicted_class': predicted_class,
            'confidence': confidence,
            'safety_score': 1 - max_danger,
            'synergy_score': avg_synergy,
            'analysis': analysis,
            'danger_score': max_danger
        }
    
    def _rule_based_analysis(self, ingredients):
        """ê·œì¹™ ê¸°ë°˜ ë¶„ì„ (ë°±ì—…)"""
        safety_issues = []
        synergy_benefits = []
        
        for i, ing1 in enumerate(ingredients):
            for ing2 in ingredients[i+1:]:
                # ìœ„í—˜í•œ ì¡°í•© ì²´í¬
                if (ing1, ing2) in self.known_dangerous_combinations:
                    info = self.known_dangerous_combinations[(ing1, ing2)]
                    safety_issues.append(f"{ing1} + {ing2}: {info['reason']}")
                elif (ing2, ing1) in self.known_dangerous_combinations:
                    info = self.known_dangerous_combinations[(ing2, ing1)]
                    safety_issues.append(f"{ing1} + {ing2}: {info['reason']}")
                
                # ì‹œë„ˆì§€ ì¡°í•© ì²´í¬
                if (ing1, ing2) in self.known_synergy_combinations:
                    info = self.known_synergy_combinations[(ing1, ing2)]
                    synergy_benefits.append(f"{ing1} + {ing2}: {info['reason']}")
                elif (ing2, ing1) in self.known_synergy_combinations:
                    info = self.known_synergy_combinations[(ing2, ing1)]
                    synergy_benefits.append(f"{ing1} + {ing2}: {info['reason']}")
        
        # ì ìˆ˜ ê³„ì‚°
        danger_score = len(safety_issues) * 0.3
        synergy_score = len(synergy_benefits) * 0.2
        
        if danger_score > 0.6:
            predicted_class = 'ìœ„í—˜'
        elif danger_score > 0.3:
            predicted_class = 'ì£¼ì˜'
        else:
            predicted_class = 'ì•ˆì „'
        
        return {
            'predicted_class': predicted_class,
            'confidence': 0.8,
            'safety_score': max(0, 1 - danger_score),
            'synergy_score': min(1, synergy_score),
            'safety_issues': safety_issues,
            'synergy_benefits': synergy_benefits,
            'analysis': f"ê·œì¹™ ê¸°ë°˜ ë¶„ì„: {predicted_class}"
        }
    
    def save_model(self, model_path):
        """ëª¨ë¸ ì €ì¥"""
        if self.model is not None:
            torch.save({
                'model_state_dict': self.model.state_dict(),
                'vocab': self.vocab,
                'vocab_to_idx': self.vocab_to_idx
            }, model_path)
            print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")
    
    def load_model(self, model_path):
        """ëª¨ë¸ ë¡œë“œ"""
        if os.path.exists(model_path):
            checkpoint = torch.load(model_path, map_location='cpu')
            self.vocab = checkpoint['vocab']
            self.vocab_to_idx = checkpoint['vocab_to_idx']
            self.idx_to_vocab = {idx: ing for ing, idx in self.vocab_to_idx.items()}
            
            self.model = IngredientInteractionModel(len(self.vocab))
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.eval()
            print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
        else:
            print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    analyzer = AdvancedCosmeticAnalyzer()
    
    # ê°„ë‹¨í•œ ì–´íœ˜ë¡œ í…ŒìŠ¤íŠ¸
    test_vocab = ['ë¹„íƒ€ë¯¼C', 'ë ˆí‹°ë†€', 'íˆì•Œë£¨ë¡ ì‚°', 'ì„¸ë¼ë§ˆì´ë“œ', 'ë‚˜ì´ì•„ì‹ ì•„ë§ˆì´ë“œ', 'AHA', 'BHA']
    
    # ëª¨ë¸ í›ˆë ¨
    model = analyzer.train_model(test_vocab, num_epochs=20)
    
    # í…ŒìŠ¤íŠ¸
    test_ingredients = ['ë¹„íƒ€ë¯¼C', 'ë ˆí‹°ë†€', 'íˆì•Œë£¨ë¡ ì‚°']
    result = analyzer.analyze_combination(test_ingredients)
    
    print(f"\nğŸ§ª ë”¥ëŸ¬ë‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    print(f"ì„±ë¶„: {test_ingredients}")
    print(f"ë¶„ë¥˜: {result['predicted_class']}")
    print(f"ìœ„í—˜ë„: {result['danger_score']:.1%}")
    print(f"ì‹œë„ˆì§€: {result['synergy_score']:.1%}")
    print(f"ë¶„ì„: {result['analysis']}")
