{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9817042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 정리 후: 라로슈포제 시카플라스트 멀티 리페어 크림\n",
      "2. 정리 후: 에스네이처 아쿠아 스쿠알란 수분크림\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_product_name_final(product_name):\n",
    "    \"\"\"제품명에서 모든 부가 설명을 제거하고 핵심 제품명만 추출합니다.\"\"\"\n",
    "    name = product_name\n",
    "\n",
    "    # 1. 괄호와 대괄호 안의 내용 전체 제거: 기획/증정/세트 정보 삭제\n",
    "    name = re.sub(r'\\[.*?\\]', '', name).strip()\n",
    "    name = re.sub(r'\\(.*?\\)', '', name).strip()\n",
    "\n",
    "    # 2. 용량 및 수량 정보 제거: 100ml, 50g, 2ea 등 숫자+단위 제거\n",
    "    # 숫자가 포함된 용량 단위 패턴을 제거합니다. (100ml, 50g 등)\n",
    "    name = re.sub(r'\\s*\\d+[\\s\\d]*[mMgG][lLgG]|[\\s\\d]*[eE][aA]', '', name, flags=re.IGNORECASE).strip()\n",
    "\n",
    "    # 3. 핵심 마케팅 키워드 제거\n",
    "    # 자주 등장하는 마케팅/부가 설명 키워드를 제거합니다.\n",
    "    keywords_to_remove = ['기획', '증정', '대용량', '더블', '세트', '단품', '올영픽', '리즈PICK', '수분광', '수분천재크림', '점보']\n",
    "    for keyword in keywords_to_remove:\n",
    "        # 단어 경계(\\b)로 정확하게 키워드만 제거\n",
    "        name = re.sub(r'\\b' + re.escape(keyword) + r'\\b', '', name, flags=re.IGNORECASE).strip()\n",
    "\n",
    "    # 4. 연속된 공백을 하나로 줄이고 최종 정리\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    \n",
    "    return name if name else product_name\n",
    "\n",
    "# 예시: 라로슈포제 시카플라스트 멀티 리페어 크림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0ed426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_split_ingredients(ingredients_list, api_ingredient_names):\n",
    "    \"\"\"\n",
    "    성분 리스트를 분해하고 불순물을 제거하며, 공공 API 명칭을 기준으로 검증합니다.\n",
    "    \n",
    "    :param ingredients_list: 스크래핑된 원본 성분 리스트 (예: [\"정제수 다이카프릴릴에터\", \"스쿠알란(150,000ppm)\"])\n",
    "    :param api_ingredient_names: 공공 API에서 추출한 표준 성분명 리스트 (Set 형태 권장)\n",
    "    :return: 정제된 성분 리스트\n",
    "    \"\"\"\n",
    "    \n",
    "    # 공공 API에서 가져온 성분명 리스트를 Set으로 변환하여 빠른 검색에 사용\n",
    "    api_set = set(api_ingredient_names)\n",
    "    \n",
    "    # 1. 단일 텍스트로 결합 및 불순물 제거 준비\n",
    "    # 리스트를 하나의 문자열로 결합하고, 불필요한 공백이나 개행문자를 제거합니다.\n",
    "    raw_text = ' '.join(ingredients_list).replace('\\n', ' ').strip()\n",
    "    \n",
    "    # ppm 등 농도 정보와 괄호 내부의 내용 제거 (성분명 분리에 방해되는 요소)\n",
    "    raw_text = re.sub(r'\\([^)]*\\)', ' ', raw_text).strip()\n",
    "    # 대괄호 안의 내용도 제거\n",
    "    raw_text = re.sub(r'\\[.*?\\]', ' ', raw_text).strip()\n",
    "    \n",
    "    # 제품명/용량과 성분명이 붙어있는 경우를 대비해 자주 보이는 구분자(숫자, 용량단위 등)를 공백으로 치환\n",
    "    raw_text = re.sub(r'\\d+[\\s\\d]*[mMgG][lLgG]|\\d+[\\s\\d]*[eE][aA]', ' ', raw_text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # 2. 성분명으로 텍스트 재분리 (핵심 로직)\n",
    "    tokenized_ingredients = set()\n",
    "    current_text = raw_text\n",
    "    \n",
    "    # API 성분명과 매칭하여 성분 추출: 긴 성분명이 먼저 매칭되도록 길이 순으로 정렬\n",
    "    # '소듐하이알루로네이트'가 '소듐'보다 먼저 추출되어야 정확합니다.\n",
    "    sorted_api_list = sorted(list(api_set), key=len, reverse=True)\n",
    "\n",
    "    for api_name in sorted_api_list:\n",
    "        # 단어 경계(\\b)를 사용하여 정확하게 성분명과 일치하는지 확인\n",
    "        if re.search(r'\\b' + re.escape(api_name) + r'\\b', current_text):\n",
    "            tokenized_ingredients.add(api_name)\n",
    "            # 매칭된 성분명을 공백으로 치환하여 중복 매칭과 잔여 텍스트 오류를 방지\n",
    "            current_text = re.sub(r'\\b' + re.escape(api_name) + r'\\b', ' ', current_text)\n",
    "\n",
    "    # 3. 최종 불순물 제거 및 리스트 정리\n",
    "    cleaned_list = []\n",
    "    for item in tokenized_ingredients:\n",
    "        item = item.strip()\n",
    "        \n",
    "        # 숫자로만 이루어진 잔여물이나 너무 짧은 단어(3자 이하) 제거\n",
    "        if re.fullmatch(r'^\\d+[\\s\\d]*$', item) or len(item) <= 3:\n",
    "            continue\n",
    "        \n",
    "        # 최종적으로 API 표준 목록에 포함된 성분만 인정하여 중복 검증\n",
    "        if item in api_set:\n",
    "            cleaned_list.append(item)\n",
    "            \n",
    "    # 최종 중복 제거 및 정렬\n",
    "    return sorted(list(set(cleaned_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc516be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re # 정규 표현식 라이브러리\n",
    "\n",
    "# --- 설정 (파일 이름은 실제 파일명에 맞게 수정하세요) ---\n",
    "COOS_FILE = \"coos_ingredient_database_final.csv\"\n",
    "OLIVE_YOUNG_FILE = \"oliveyoung_products.csv\" # ⚠️ 실제 올리브영 파일명으로 수정 필요\n",
    "OUTPUT_FILE = \"integrated_cosmetic_data.csv\"\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 0. 데이터 불러오기\n",
    "# ----------------------------------------------------------------------\n",
    "try:\n",
    "    # COOS 성분 데이터 (스크래핑 결과)\n",
    "    df_coos = pd.read_csv(COOS_FILE)\n",
    "    print(f\"COOS 데이터 로드 완료: {len(df_coos)}개 성분\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ 오류: COOS 파일 '{COOS_FILE}'을 찾을 수 없습니다. 파일명을 확인해 주세요.\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    # 올리브영 상품 데이터 (이전에 스크래핑했던 결과)\n",
    "    # ⚠️ 이 파일은 '상품명', '가격', '성분_목록' (콤마로 구분된 성분 리스트) 컬럼이 있다고 가정합니다.\n",
    "    df_oly = pd.read_csv(OLIVE_YOUNG_FILE)\n",
    "    print(f\"올리브영 데이터 로드 완료: {len(df_oly)}개 상품\")\n",
    "except FileNotFoundError:\n",
    "    # 테스트를 위해 올리브영 데이터가 없을 경우 가상 데이터 생성\n",
    "    print(f\"⚠️ 올리브영 파일 '{OLIVE_YOUNG_FILE}'이 없어 가상 데이터를 생성합니다.\")\n",
    "    df_oly = pd.DataFrame({\n",
    "        '상품ID': [101, 102, 103],\n",
    "        '상품명': ['A사 수딩 크림', 'B사 톤업 선크림', 'C사 샴푸'],\n",
    "        '브랜드': ['A사', 'B사', 'C사'],\n",
    "        '가격': [25000, 32000, 18000],\n",
    "        # COOS 데이터와 매칭 테스트를 위한 성분 목록\n",
    "        '성분_목록': [\n",
    "            \"정제수, 글리세린, 히비스커스꽃추출물, 히스티딘, 토코페롤\",\n",
    "            \"정제수, 징크옥사이드, 티타늄디옥사이드, 흰버드나무껍질추출물, 나이아신아마이드\",\n",
    "            \"라우릴글루코사이드, 코카미도프로필베타인, 정제수\"\n",
    "        ]\n",
    "    })\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1단계: COOS 데이터 클리닝 및 표준화\n",
    "# ----------------------------------------------------------------------\n",
    "print(\"\\n[1단계] COOS 성분 데이터 정리 시작...\")\n",
    "\n",
    "# 1. 태그 목록 정리 (불필요한 노이즈 제거)\n",
    "# 스크래핑 코드에서 이미 필터링했으나, 혹시 모를 잔여 노이즈를 정리합니다.\n",
    "def clean_tags(tags):\n",
    "    if not isinstance(tags, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # 콤마로 분리 후 불필요한 패턴 제거\n",
    "    tags_list = [t.strip() for t in tags.split(',')]\n",
    "    \n",
    "    # 길이가 짧거나, 특정 코드가 포함된 태그를 다시 제거 (예: AI, KO, EN, 식, 가능, 불가)\n",
    "    NOISE_PATTERNS = re.compile(r'^(AI|KO|EN|JP|EU|식|가능|불가|EWG)$', re.IGNORECASE)\n",
    "    \n",
    "    cleaned_tags = [\n",
    "        t for t in tags_list \n",
    "        if t and len(t) > 2 and not NOISE_PATTERNS.match(t)\n",
    "    ]\n",
    "    return ', '.join(cleaned_tags)\n",
    "\n",
    "df_coos['태그_목록_정리'] = df_coos['태그_목록'].apply(clean_tags)\n",
    "\n",
    "# 2. 표준 성분명 컬럼 생성 (조인을 위한 키)\n",
    "# 원료명, 영문명 모두 공백, 괄호 등을 제거하여 조인 시 오류를 줄일 수 있습니다.\n",
    "def create_standard_name(name):\n",
    "    if not isinstance(name, str):\n",
    "        return None\n",
    "    # 띄어쓰기, 괄호 제거 후 소문자 변환\n",
    "    return re.sub(r'[\\s\\(\\)\\[\\]]+', '', name).lower()\n",
    "\n",
    "df_coos['표준성분명'] = df_coos['원료명'].apply(create_standard_name)\n",
    "\n",
    "print(\"COOS 데이터 정리 및 표준 성분 키 생성 완료.\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2단계: 올리브영 데이터 성분 목록 분리 (Explode)\n",
    "# ----------------------------------------------------------------------\n",
    "print(\"\\n[2단계] 올리브영 성분 목록 분리 시작...\")\n",
    "\n",
    "# 1. '성분_목록' 컬럼을 콤마(,) 기준으로 리스트로 변환\n",
    "df_oly['성분_리스트'] = df_oly['성분_목록'].str.split(r',(?![^\\(]*\\))') \n",
    "# (팁: 괄호 안의 콤마는 분리하지 않는 정규표현식, 복잡한 성분명 처리)\n",
    "\n",
    "# 2. explode (데이터 폭발): 하나의 상품을 여러 성분 행으로 분리\n",
    "df_oly_exploded = df_oly.explode('성분_리스트')\n",
    "\n",
    "# 3. 분리된 성분명 클리닝 및 표준 성분 키 생성\n",
    "df_oly_exploded['원료명'] = df_oly_exploded['성분_리스트'].str.strip()\n",
    "df_oly_exploded['표준성분명'] = df_oly_exploded['원료명'].apply(create_standard_name)\n",
    "\n",
    "# 불필요한 행(빈 성분명) 제거\n",
    "df_oly_exploded.dropna(subset=['표준성분명'], inplace=True)\n",
    "\n",
    "print(f\"올리브영 데이터 폭발 완료. 총 {len(df_oly_exploded)}개의 성분 항목 생성.\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3단계: 표준 성분 매핑 및 데이터 통합 (JOIN)\n",
    "# ----------------------------------------------------------------------\n",
    "print(\"\\n[3단계] 두 데이터셋 통합(Merge) 시작...\")\n",
    "\n",
    "# COOS 데이터에서 필요한 컬럼만 선택 (중복 조인을 막기 위해)\n",
    "coos_cols = ['표준성분명', '원료명', '영문명', 'CAS_No', '설명_요약', '태그_목록_정리', '상세_URL']\n",
    "df_coos_clean = df_coos[coos_cols].rename(columns={'원료명': 'COOS_원료명'}).drop_duplicates(subset=['표준성분명'])\n",
    "\n",
    "\n",
    "# 올리브영 상품 데이터와 COOS 성분 데이터를 '표준성분명'을 기준으로 Left Join\n",
    "# Left Join을 사용하면, COOS 데이터에 없는 성분이라도 올리브영 상품 정보는 유지됩니다.\n",
    "df_final = pd.merge(\n",
    "    df_oly_exploded, \n",
    "    df_coos_clean, \n",
    "    on='표준성분명', \n",
    "    how='left', \n",
    "    suffixes=('_OLY', '_COOS')\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 4. 최종 정리 및 저장\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# 최종 컬럼 순서 지정 및 정리\n",
    "df_final = df_final.rename(columns={'원료명_OLY': '사용_원료명_OLY'})\n",
    "\n",
    "final_columns = [\n",
    "    '상품명', '브랜드', '가격', # 상품 정보\n",
    "    '사용_원료명_OLY', 'COOS_원료명', # 매핑된 성분명\n",
    "    '영문명', 'CAS_No', '설명_요약', '태그_목록_정리', # COOS 성분 속성\n",
    "    '상세_URL' # COOS 링크\n",
    "]\n",
    "\n",
    "df_final = df_final[[col for col in final_columns if col in df_final.columns]]\n",
    "\n",
    "# 매핑되지 않은 성분에 대한 처리 (COOS 정보가 없는 경우)\n",
    "df_final['COOS_매칭여부'] = np.where(df_final['CAS_No'].isnull(), '미매칭', '매칭완료')\n",
    "\n",
    "df_final.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"\\n==================================================\")\n",
    "print(f\"✅ 데이터 통합 및 표준화 완료!\")\n",
    "print(f\"최종 통합 데이터셋 크기: {len(df_final)} 행\")\n",
    "print(f\"결과 파일: {OUTPUT_FILE}\")\n",
    "print(\"==================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3adb6a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.2단계] COOS 데이터 로드 완료: 25750개 성분\n",
      "\n",
      "[0.1단계] 올리브영 JSON 파일 통합 시작...\n",
      "✅ 총 2187개 상품 통합 완료.\n",
      "   ⚠️ 경고: '성분_목록' 컬럼 대신 '성분리스트' 컬럼을 사용하여 이름을 변경했습니다.\n",
      "   [1.6단계] 메타데이터 컬럼 표준화 시작...\n",
      "      - '제품명'을(를) '상품명'으로(로) 변경했습니다.\n",
      "   ✅ 메타데이터 표준화 완료 (상품명만 존재 확인).\n",
      "\n",
      "[1단계] COOS 성분 데이터 정리 및 표준화 시작...\n",
      "\n",
      "[2단계] 올리브영 성분 목록 분리 및 매핑 키 생성...\n",
      "\n",
      "[3단계] 성분 속성 연결을 위한 최종 데이터셋 병합...\n",
      "✅ 최종 통합 및 정규화된 데이터셋 크기: 90507 행\n",
      "\n",
      "==================================================\n",
      "✅ 데이터 통합 및 정규화 완료!\n",
      "결과 파일: integrated_product_ingredient_normalized.csv\n",
      "이 파일은 '상품' - '개별 성분' 단위로 정규화되어 있으며, NameError 문제가 해결되었습니다.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "from itertools import combinations \n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# --- 설정 ---\n",
    "# ----------------------------------------------------------------------\n",
    "# COOS 데이터베이스 파일\n",
    "COOS_FILE = \"coos_ingredient_database.csv\"\n",
    "\n",
    "# 올리브영 JSON 파일 목록\n",
    "OLIVE_YOUNG_FILES = [\n",
    "    \"oliveyoung_로션_raw_limited.json\",\n",
    "    \"oliveyoung_미스트_오일_raw_limited.json\",\n",
    "    \"oliveyoung_스킨_토너_raw_limited.json\",\n",
    "    \"oliveyoung_에센스_세럼_앰플_raw_limited.json\",\n",
    "    \"oliveyoung_크림_raw_limited.json\",\n",
    "]\n",
    "OUTPUT_FILE = \"integrated_product_ingredient_normalized.csv\"\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# --- 데이터 클리닝 유틸리티 (Normalization Functions) ---\n",
    "# data_cleaner_utils.py 파일의 내용을 그대로 포함합니다.\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def clean_tags(tags):\n",
    "    \"\"\"\n",
    "    COOS 데이터의 태그 목록에서 불필요한 노이즈를 제거하고 정리합니다.\n",
    "    \"\"\"\n",
    "    if not isinstance(tags, str): return \"\"\n",
    "    tags_list = [t.strip() for t in tags.split(',')]\n",
    "    # 불필요한 패턴(AI, KO, JP 등) 및 짧은 태그 제거를 위한 정규식\n",
    "    NOISE_PATTERNS = re.compile(r'^(AI|KO|EN|JP|EU|식|가능|불가|EWG|EWG-Green)$', re.IGNORECASE)\n",
    "    cleaned_tags = [\n",
    "        t for t in tags_list \n",
    "        if t and len(t) > 2 and not NOISE_PATTERNS.match(t)\n",
    "    ]\n",
    "    return ', '.join(cleaned_tags)\n",
    "\n",
    "def create_standard_name(name):\n",
    "    \"\"\"\n",
    "    성분명에서 특수문자 등을 제거하고 소문자화하여 표준 매핑 키(Standard Key)를 만듭니다.\n",
    "    \"\"\"\n",
    "    if not isinstance(name, str): return None\n",
    "    # 문자, 숫자, 한글, 영어 외의 모든 문자를 공백으로 치환 후 제거\n",
    "    cleaned_name = re.sub(r'[^\\w가-힣]+', '', name).lower()\n",
    "    return cleaned_name\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# --- 데이터 로딩 및 통합 함수 ---\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def load_and_consolidate_oliveyoung_data(file_list):\n",
    "    \"\"\"여러 올리브영 JSON 파일을 통합하고 카테고리 정보를 추가합니다.\"\"\"\n",
    "    all_dfs = []\n",
    "    print(\"\\n[0.1단계] 올리브영 JSON 파일 통합 시작...\")\n",
    "    for file_path in file_list:\n",
    "        try:\n",
    "            base_name = os.path.basename(file_path)\n",
    "            # 파일명에서 카테고리 추출\n",
    "            category_part = base_name.replace('oliveyoung_', '').replace('_raw_limited.json', '')\n",
    "            category_name = category_part.replace('_', '/')\n",
    "\n",
    "            df = pd.read_json(file_path, encoding='utf-8')\n",
    "            df['카테고리'] = category_name\n",
    "            all_dfs.append(df)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"   ❌ 경고: 파일 '{file_path}'을 찾을 수 없습니다. 건너뜁니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ 경고: 파일 '{file_path}' 로드 중 오류 발생: {e}. 건너뜁니다.\")\n",
    "            \n",
    "    if not all_dfs:\n",
    "        print(\"   ❌ 오류: 로드된 올리브영 데이터가 없습니다. 스크립트를 종료합니다.\")\n",
    "        return None\n",
    "        \n",
    "    df_consolidated = pd.concat(all_dfs, ignore_index=True)\n",
    "    if '상품ID' not in df_consolidated.columns:\n",
    "        df_consolidated['상품ID'] = df_consolidated.index.astype(str)\n",
    "        \n",
    "    print(f\"✅ 총 {len(df_consolidated)}개 상품 통합 완료.\")\n",
    "    return df_consolidated\n",
    "\n",
    "def clean_and_standardize_coos(df_coos):\n",
    "    \"\"\"COOS 데이터를 클리닝하고 표준 매핑 키를 생성합니다.\"\"\"\n",
    "    print(\"\\n[1단계] COOS 성분 데이터 정리 및 표준화 시작...\")\n",
    "    \n",
    "    # 1. 태그 정리 및 표준 성분명(매핑 키) 생성\n",
    "    df_coos['태그_목록_정리'] = df_coos['태그_목록'].apply(clean_tags)\n",
    "    df_coos['표준성분명'] = df_coos['원료명'].apply(create_standard_name)\n",
    "    \n",
    "    # 2. 모델에 필요한 속성 컬럼 정의\n",
    "    coos_cols = ['표준성분명', '원료명', '영문명', 'CAS_No', '설명_요약', '태그_목록_정리', '상세_URL']\n",
    "    df_coos_clean = df_coos[coos_cols].rename(columns={'원료명': 'COOS_원료명'}).drop_duplicates(subset=['표준성분명'], keep='first')\n",
    "    \n",
    "    return df_coos_clean\n",
    "\n",
    "def verify_and_rename_ingredient_column(df, expected_col='성분_목록'):\n",
    "    \"\"\"\n",
    "    df에 필수 성분 컬럼이 있는지 확인하고, 없으면 대안 컬럼을 찾아 이름을 변경합니다.\n",
    "    \"\"\"\n",
    "    if expected_col in df.columns:\n",
    "        return df\n",
    "\n",
    "    # 스크래핑 데이터에서 흔히 사용되는 대안 이름 목록 (성분리스트 추가)\n",
    "    ALTERNATIVE_NAMES = ['성분리스트', 'ingredients', '전성분', 'Ingredient_List', '성분목록']\n",
    "    \n",
    "    found_alt = None\n",
    "    for alt in ALTERNATIVE_NAMES:\n",
    "        if alt in df.columns:\n",
    "            df.rename(columns={alt: expected_col}, inplace=True)\n",
    "            print(f\"   ⚠️ 경고: '{expected_col}' 컬럼 대신 '{alt}' 컬럼을 사용하여 이름을 변경했습니다.\")\n",
    "            found_alt = True\n",
    "            break\n",
    "    \n",
    "    if not found_alt:\n",
    "        print(f\"   ❌ 치명적 오류: 통합된 올리브영 데이터에 필수 컬럼 '{expected_col}' 또는 그 대안이 없습니다.\")\n",
    "        print(f\"   현재 컬럼 목록: {df.columns.tolist()}\")\n",
    "        # KeyError를 다시 발생시켜 메인 블록에서 처리하도록 함\n",
    "        raise KeyError(expected_col) \n",
    "\n",
    "    return df\n",
    "\n",
    "def verify_and_rename_metadata_columns(df):\n",
    "    \"\"\"\n",
    "    상품 메타데이터 컬럼 중 존재하는 컬럼(제품명)만 확인하고 표준화합니다.\n",
    "    (브랜드, 가격, 리뷰수, 평점은 데이터에 없으므로 체크하지 않음)\n",
    "    \"\"\"\n",
    "    # {표준이름: [대안 이름 목록]}\n",
    "    REQUIRED_MAPPING = {\n",
    "        # 사용자 피드백에 따라, 존재하는 '제품명'만 '상품명'으로 표준화합니다.\n",
    "        '상품명': ['제품명', 'name', 'product_name'],\n",
    "    }\n",
    "    \n",
    "    current_cols = df.columns.tolist()\n",
    "    \n",
    "    print(\"   [1.6단계] 메타데이터 컬럼 표준화 시작...\")\n",
    "\n",
    "    # 필수 컬럼 검사 및 이름 변경\n",
    "    for expected, alternatives in REQUIRED_MAPPING.items():\n",
    "        if expected not in current_cols:\n",
    "            for alt in alternatives:\n",
    "                if alt in current_cols:\n",
    "                    df.rename(columns={alt: expected}, inplace=True)\n",
    "                    print(f\"      - '{alt}'을(를) '{expected}'으로(로) 변경했습니다.\")\n",
    "                    break\n",
    "    \n",
    "    # 누락된 컬럼(브랜드, 가격, 리뷰수, 평점)에 대한 경고는 생략합니다.\n",
    "    print(\"   ✅ 메타데이터 표준화 완료 (상품명만 존재 확인).\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# --- 메인 실행 로직 ---\n",
    "# ----------------------------------------------------------------------\n",
    "def main():\n",
    "    \n",
    "    # 0. 데이터 로드\n",
    "    df_coos = None # NameError 방지를 위해 초기화\n",
    "    try:\n",
    "        df_coos = pd.read_csv(COOS_FILE)\n",
    "        print(f\"\\n[0.2단계] COOS 데이터 로드 완료: {len(df_coos)}개 성분\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\n❌ 오류: COOS 파일 '{COOS_FILE}'을 찾을 수 없습니다. 파일명을 확인해 주세요.\")\n",
    "        return # main() 함수 내부에서는 return 사용 가능\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ 오류: COOS 파일 로드 중 예상치 못한 오류 발생: {e}\")\n",
    "        return # main() 함수 내부에서는 return 사용 가능\n",
    "\n",
    "    df_oly = load_and_consolidate_oliveyoung_data(OLIVE_YOUNG_FILES)\n",
    "    if df_oly is None: return # main() 함수 내부에서는 return 사용 가능\n",
    "\n",
    "    # 1.5단계: 필수 성분 컬럼 확인 및 이름 변경 (성분 목록 키 표준화)\n",
    "    try:\n",
    "        df_oly = verify_and_rename_ingredient_column(df_oly, expected_col='성분_목록')\n",
    "    except KeyError as e:\n",
    "        print(\"\\n   ⚠️ 데이터 오류로 인해 스크립트를 종료합니다. JSON 파일의 성분 목록 키를 확인하세요.\")\n",
    "        return # main() 함수 내부에서는 return 사용 가능\n",
    "    \n",
    "    # 1.6단계: 상품 메타데이터 컬럼 확인 및 이름 변경 (에러 방지 로직)\n",
    "    df_oly = verify_and_rename_metadata_columns(df_oly)\n",
    "\n",
    "    \n",
    "    # 1. COOS 데이터 클리닝 및 표준화\n",
    "    df_coos_clean = clean_and_standardize_coos(df_coos)\n",
    "    \n",
    "    # 2. 올리브영 성분 목록 분리 및 매핑 키 생성\n",
    "    print(\"\\n[2단계] 올리브영 성분 목록 분리 및 매핑 키 생성...\")\n",
    "    \n",
    "    # 성분 목록이 이미 리스트 형태이므로, str.split() 과정 없이 바로 explode 수행\n",
    "    # .copy()를 사용하여 SettingWithCopyWarning 방지\n",
    "    df_oly_exploded = df_oly.explode('성분_목록').copy()\n",
    "    \n",
    "    # 펼쳐진 성분 컬럼의 값을 '사용_원료명' 컬럼에 복사하고 공백 제거\n",
    "    # 혹시 모를 타입 문제를 대비해 astype(str) 적용\n",
    "    df_oly_exploded['사용_원료명'] = df_oly_exploded['성분_목록'].astype(str).str.strip()\n",
    "    \n",
    "    # 표준 매핑 키 생성\n",
    "    df_oly_exploded['표준_매핑_키'] = df_oly_exploded['사용_원료명'].apply(create_standard_name)\n",
    "    df_oly_exploded.dropna(subset=['표준_매핑_키'], inplace=True)\n",
    "    \n",
    "    # 3. 올리브영 성분과 COOS 데이터 통합 (병합)\n",
    "    print(\"\\n[3단계] 성분 속성 연결을 위한 최종 데이터셋 병합...\")\n",
    "    \n",
    "    # 병합할 올리브영 컬럼 - (브랜드, 가격, 리뷰수, 평점)은 데이터에 없으므로 제외합니다.\n",
    "    existing_oly_cols = ['상품ID', '상품명', '카테고리', '사용_원료명', '표준_매핑_키']\n",
    "    \n",
    "    # 실제 df_oly_exploded에 존재하는 컬럼만 선택 (상품명만 매핑되었으므로)\n",
    "    df_oly_slim = df_oly_exploded[[col for col in existing_oly_cols if col in df_oly_exploded.columns]]\n",
    "\n",
    "    # 표준 매핑 키를 기준으로 COOS 속성 병합\n",
    "    df_final_normalized = df_oly_slim.merge(\n",
    "        df_coos_clean, \n",
    "        left_on='표준_매핑_키', \n",
    "        right_on='표준성분명', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 4. 최종 컬럼 정리 및 저장\n",
    "    # 불필요한 중복 키 제거 (표준성분명 == 표준_매핑_키 이므로 하나만 남김)\n",
    "    df_final_normalized.drop(columns=['표준성분명', '성분_목록', 'URL'], inplace=True, errors='ignore') \n",
    "    \n",
    "    print(f\"✅ 최종 통합 및 정규화된 데이터셋 크기: {len(df_final_normalized)} 행\")\n",
    "    \n",
    "    df_final_normalized.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"\\n==================================================\")\n",
    "    print(f\"✅ 데이터 통합 및 정규화 완료!\")\n",
    "    print(f\"결과 파일: {OUTPUT_FILE}\")\n",
    "    print(\"이 파일은 '상품' - '개별 성분' 단위로 정규화되어 있으며, NameError 문제가 해결되었습니다.\")\n",
    "    print(\"==================================================\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# --- 메인 실행 블록 ---\n",
    "# ----------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d6c0434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.2단계] COOS 데이터 로드 완료: 25750개 성분\n",
      "\n",
      "[0.1단계] 올리브영 JSON 파일 통합 시작...\n",
      "✅ 총 2187개 상품 통합 완료.\n",
      "   ⚠️ 경고: '성분_목록' 컬럼 대신 '성분리스트' 컬럼을 사용하여 이름을 변경했습니다.\n",
      "   [1.6단계] 메타데이터 컬럼 표준화 시작...\n",
      "      - '제품명'을(를) '상품명'으로(로) 변경했습니다.\n",
      "   ✅ 메타데이터 표준화 완료 (상품명만 존재 확인).\n",
      "\n",
      "[1단계] COOS 성분 데이터 정리 및 표준화 시작...\n",
      "\n",
      "[2단계] 키트 분리, 성분 폭발, 표준화 시작...\n",
      "   ✅ 키트 분리 및 성분 폭발 완료. 총 4644개의 성분 레코드 생성.\n",
      "\n",
      "[3단계] 성분 속성 연결을 위한 최종 데이터셋 병합...\n",
      "✅ 최종 통합 및 정규화된 데이터셋 크기: 4644 행\n",
      "\n",
      "==================================================\n",
      "✅ 데이터 통합 및 정규화 완료!\n",
      "결과 파일: integrated_product_ingredient_normalized.csv\n",
      "브랜드명, 제품명, 개별 성분(COOS 속성 포함)을 기준으로 데이터가 완벽하게 정규화되었습니다.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "from itertools import combinations \n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# --- 설정 ---\n",
    "# ----------------------------------------------------------------------\n",
    "# COOS 데이터베이스 파일 (사용자 제공 파일명)\n",
    "COOS_FILE = \"coos_ingredient_database.csv\"\n",
    "\n",
    "# 올리브영 JSON 파일 목록 (사용자 제공 파일명)\n",
    "OLIVE_YOUNG_FILES = [\n",
    "    \"oliveyoung_로션_raw_limited.json\",\n",
    "    \"oliveyoung_미스트_오일_raw_limited.json\",\n",
    "    \"oliveyoung_스킨_토너_raw_limited.json\",\n",
    "    \"oliveyoung_에센스_세럼_앰플_raw_limited.json\",\n",
    "    \"oliveyoung_크림_raw_limited.json\",\n",
    "]\n",
    "OUTPUT_FILE = \"integrated_product_ingredient_normalized.csv\"\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# --- 데이터 클리닝 유틸리티 (Normalization Functions) ---\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def clean_tags(tags):\n",
    "    \"\"\"COOS 데이터의 태그 목록에서 불필요한 노이즈를 제거합니다.\"\"\"\n",
    "    if not isinstance(tags, str): return \"\"\n",
    "    tags_list = [t.strip() for t in tags.split(',')]\n",
    "    # EWG-Green 태그는 남기고, EWG 등 불필요한 패턴 제거\n",
    "    NOISE_PATTERNS = re.compile(r'^(AI|KO|EN|JP|EU|식|가능|불가|EWG|EWG-Green)$', re.IGNORECASE)\n",
    "    cleaned_tags = [t for t in tags_list if t and len(t) > 2 and not NOISE_PATTERNS.match(t)]\n",
    "    return ', '.join(cleaned_tags)\n",
    "\n",
    "def create_standard_name(name):\n",
    "    \"\"\"성분명에서 특수문자 등을 제거하고 소문자화하여 표준 매핑 키(Standard Key)를 만듭니다.\"\"\"\n",
    "    if not isinstance(name, str): return None\n",
    "    # 괄호와 그 안의 내용 제거 (예: 정제수(달팽이점액여과물) -> 정제수)\n",
    "    name = re.sub(r'\\(.*?\\)', '', name).strip()\n",
    "    # 문자, 숫자, 한글, 영어 외의 모든 문자를 공백으로 치환 후 제거\n",
    "    cleaned_name = re.sub(r'[^\\w가-힣]+', '', name).lower()\n",
    "    return cleaned_name\n",
    "\n",
    "def parse_brand_and_name(full_name):\n",
    "    \"\"\"\n",
    "    상품명에서 불필요한 기획/증정 정보를 제거하고 브랜드와 제품명을 분리합니다.\n",
    "    \"\"\"\n",
    "    if not isinstance(full_name, str):\n",
    "        return None, None\n",
    "    \n",
    "    # 1. []나 () 안에 있는 노이즈 제거 (예: [1등올인원], (+100ml증정))\n",
    "    cleaned_name = re.sub(r'\\[.*?\\]|\\(.*?\\)', '', full_name).strip()\n",
    "    \n",
    "    # 2. '기획세트', '세트', '증정', '대용량', '본품' 등 상품의 특성 관련 단어 제거\n",
    "    noise_words = ['기획세트', '기획', '세트', '증정', '대용량', '본품', '단품']\n",
    "    for word in noise_words:\n",
    "        cleaned_name = cleaned_name.replace(word, ' ').strip()\n",
    "    \n",
    "    # 여러 개의 공백을 하나로 줄임\n",
    "    cleaned_name = re.sub(r'\\s+', ' ', cleaned_name).strip()\n",
    "    \n",
    "    # 3. 브랜드명 (첫 번째 단어) 추출 및 제품명 (나머지 부분) 추출\n",
    "    parts = cleaned_name.split(maxsplit=1)\n",
    "    brand = parts[0] if parts else None\n",
    "    product_name = parts[1].strip() if len(parts) > 1 else None\n",
    "    \n",
    "    return brand, product_name\n",
    "\n",
    "def preprocess_mushed_ingredients(full_string):\n",
    "    \"\"\"\n",
    "    붙어버린 성분 경계를 복구하고, 키트 마커를 정리합니다.\n",
    "    (예: '토코페롤정제수' -> '토코페롤,정제수')\n",
    "    (예: '시카크림100ml+15ml정제수' -> '시카크림100ml+15ml,정제수')\n",
    "    \"\"\"\n",
    "    # 1. 흔한 시작 성분 그룹: 이 성분들이 이전 성분이나 제품명에 붙어있을 확률이 높음\n",
    "    START_INGREDIENT_GROUP = r'(정제수|글리세린|다이카프릴릴|나이아신아마이드|메틸프로판다이올|부틸렌글라이콜|프로판다이올|펜틸렌글라이콜|스쿠알란|판테놀|토코페롤|아데노신|시트릭애씨드|소듐클로라이드|세테아릴|시트릭애씨드)'\n",
    "    \n",
    "    # 2. 정규식 패턴: (\\w) (한글,영문,숫자) 뒤에 바로 (흔한 시작 성분)이 붙어있는 경우\n",
    "    # 제품명/용량 정보('100ml') 뒤에 성분이 붙어있는 경우도 처리하기 위해 \\w 사용\n",
    "    regex = re.compile(r'(\\w)' + START_INGREDIENT_GROUP, re.UNICODE)\n",
    "    \n",
    "    # 3. 찾은 패턴을 '성분1,성분2' 형태로 대체하여 쉼표를 삽입합니다.\n",
    "    processed_string = regex.sub(r'\\1,\\2', full_string)\n",
    "    \n",
    "    # 4. 키트 제품명 마커 정리: '제품명:정제수' 형태에서 콜론 뒤에 쉼표가 없으면 추가하여 분리하기 쉽게 만듭니다.\n",
    "    processed_string = re.sub(r'([가-힣\\s]+?)\\s*:\\s*([가-힣])', r'\\1:\\2', processed_string)\n",
    "    \n",
    "    # 5. 불필요한 공백/개행 문자 제거 및 정리\n",
    "    processed_string = re.sub(r'\\s{2,}', ' ', processed_string).replace('\\n', ' ').strip()\n",
    "    \n",
    "    return processed_string\n",
    "\n",
    "def split_kit_string(ingredient_list_or_str):\n",
    "    \"\"\"\n",
    "    제품명:성분리스트가 합쳐진 문자열을 파싱하여 개별 제품 레코드를 반환합니다.\n",
    "    (콜론, 대괄호 기반 마커 분리 로직 사용)\n",
    "    \"\"\"\n",
    "    if isinstance(ingredient_list_or_str, list):\n",
    "        full_string = \" \".join([str(item) for item in ingredient_list_or_str]).strip()\n",
    "    elif isinstance(ingredient_list_or_str, str):\n",
    "        full_string = ingredient_list_or_str.strip()\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "    if not full_string:\n",
    "        return []\n",
    "        \n",
    "    # 1. **전처리:** 붙어버린 성분 경계를 복구합니다.\n",
    "    full_string = preprocess_mushed_ingredients(full_string)\n",
    "    \n",
    "    # 2. 키트 마커 패턴: '제품명:' (콜론) 또는 '[제품명]' (대괄호)\n",
    "    KIT_MARKER_PATTERN = r'([가-힣\\s]+?\\s*:)|(\\[.*?\\])'\n",
    "    \n",
    "    # 마커를 기준으로 분할하고, 마커 자체를 포함하도록 정규식 그룹을 사용\n",
    "    parts = re.split(f'({KIT_MARKER_PATTERN})', full_string)\n",
    "    \n",
    "    products = []\n",
    "    current_product_name = None\n",
    "    current_ingredients_str = \"\"\n",
    "    \n",
    "    # 분할된 문자열 처리\n",
    "    for part in parts:\n",
    "        if not part or part.isspace():\n",
    "            continue\n",
    "            \n",
    "        # 3. 제품명 마커 확인\n",
    "        \n",
    "        # Case 1: '제품명:' 형태의 마커 (예: '올인원 스틱:')\n",
    "        if part.strip().endswith(':'):\n",
    "            # 이전 제품의 성분을 처리하고 새 제품 시작\n",
    "            if current_ingredients_str and current_product_name:\n",
    "                ingredients = [ing.strip() for ing in current_ingredients_str.split(',') if ing.strip()]\n",
    "                products.append({'name': current_product_name, 'ingredients': ingredients})\n",
    "                current_ingredients_str = \"\"\n",
    "            \n",
    "            current_product_name = part.strip().replace(':', '').strip()\n",
    "            \n",
    "        # Case 2: '[제품명]' 형태의 마커\n",
    "        elif part.startswith('[') and part.endswith(']'):\n",
    "            # 이전 제품의 성분을 처리하고 새 제품 시작\n",
    "            if current_ingredients_str and current_product_name:\n",
    "                ingredients = [ing.strip() for ing in current_ingredients_str.split(',') if ing.strip()]\n",
    "                products.append({'name': current_product_name, 'ingredients': ingredients})\n",
    "                current_ingredients_str = \"\"\n",
    "            \n",
    "            current_product_name = part.strip().strip('[]').strip()\n",
    "            \n",
    "        # Case 3: 성분 문자열 (쉼표가 이미 전처리 단계에서 삽입됨)\n",
    "        else:\n",
    "            current_ingredients_str += part\n",
    "            \n",
    "    # 4. 마지막 제품의 성분 처리\n",
    "    if current_ingredients_str:\n",
    "        ingredients = [ing.strip() for ing in current_ingredients_str.split(',') if ing.strip()]\n",
    "        \n",
    "        # 성분 문자열에서 불필요한 키트 잔여물 제거 및 첫 성분 정리\n",
    "        START_INGREDIENT_GROUP_CLEAN = r'(정제수|글리세린|다이카프릴릴|나이아신아마이드|메틸프로판다이올|부틸렌글라이콜|프로판다이올|펜틸렌글라이콜|스쿠알란|판테놀|토코페롤|아데노신|시트릭애씨드|소듐클로라이드|세테아릴|시트릭애씨드)'\n",
    "        \n",
    "        if ingredients and ingredients[0] and re.match(START_INGREDIENT_GROUP_CLEAN, ingredients[0], re.IGNORECASE):\n",
    "            first_ing = ingredients[0]\n",
    "            match = re.search(START_INGREDIENT_GROUP_CLEAN, first_ing, re.IGNORECASE)\n",
    "            if match and match.start() > 0:\n",
    "                ingredients[0] = first_ing[match.start():].strip()\n",
    "\n",
    "        \n",
    "        if not products and not current_product_name:\n",
    "             # 키트 마커 없이 단일 제품으로 인식\n",
    "             products.append({'name': None, 'ingredients': ingredients})\n",
    "        elif current_product_name:\n",
    "             # 마커가 있었던 마지막 제품\n",
    "             products.append({'name': current_product_name, 'ingredients': ingredients})\n",
    "        else:\n",
    "            # 마커는 없는데 데이터가 남은 경우 (단일 제품으로 강제 처리)\n",
    "            products.append({'name': None, 'ingredients': ingredients})\n",
    "            \n",
    "    return products\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# --- 핵심 정규화 로직 함수 (누락된 부분) ---\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def split_and_normalize_kit(df_oly):\n",
    "    \"\"\"\n",
    "    올리브영 데이터프레임을 받아, 키트 제품을 개별 상품으로 분리하고,\n",
    "    각 성분을 행으로 폭발(Explode)시켜 최종 정규화된 데이터프레임을 반환합니다.\n",
    "    \"\"\"\n",
    "    print(\"\\n[2단계] 키트 분리, 성분 폭발, 표준화 시작...\")\n",
    "    \n",
    "    all_normalized_products = []\n",
    "    \n",
    "    for index, row in df_oly.iterrows():\n",
    "        # 1. 키트 분리 및 성분 추출\n",
    "        kit_products = split_kit_string(row['성분_목록'])\n",
    "        \n",
    "        # 2. 브랜드명 (원래 상품명 기준) 및 제품명(키트 분리 결과) 파싱\n",
    "        original_product_name = row['상품명']\n",
    "        original_brand, parsed_product_name = parse_brand_and_name(original_product_name)\n",
    "        \n",
    "        # 키트 분리 결과에 따라 반복 처리\n",
    "        for kit_item in kit_products:\n",
    "            # 최종 제품명 결정: 키트 분리 시 이름이 있으면 사용, 없으면 원본에서 파싱된 제품명 사용\n",
    "            final_product_name = kit_item['name'] if kit_item['name'] else parsed_product_name\n",
    "            \n",
    "            # 3. 개별 성분 폭발 및 매핑 키 생성\n",
    "            for ingredient in kit_item['ingredients']:\n",
    "                if ingredient:\n",
    "                    # 성분 데이터 레코드 생성\n",
    "                    record = {\n",
    "                        '상품ID': row.get('상품ID'),\n",
    "                        '상품명': original_product_name, # 원본 상품명 유지\n",
    "                        '브랜드명': original_brand,\n",
    "                        '제품명': final_product_name, # 정규화된 개별 제품명\n",
    "                        '카테고리': row.get('카테고리'),\n",
    "                        'URL': row.get('URL'),\n",
    "                        '사용_원료명': ingredient, # 올리브영 성분명\n",
    "                        '표준_매핑_키': create_standard_name(ingredient) # COOS 매핑을 위한 표준 키\n",
    "                    }\n",
    "                    all_normalized_products.append(record)\n",
    "\n",
    "    df_normalized = pd.DataFrame(all_normalized_products)\n",
    "    print(f\"   ✅ 키트 분리 및 성분 폭발 완료. 총 {len(df_normalized)}개의 성분 레코드 생성.\")\n",
    "    return df_normalized\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# --- 데이터 로딩 및 통합 함수 ---\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def load_and_consolidate_oliveyoung_data(file_list):\n",
    "    \"\"\"여러 올리브영 JSON 파일을 통합하고 카테고리 정보를 추가합니다.\"\"\"\n",
    "    all_dfs = []\n",
    "    print(\"\\n[0.1단계] 올리브영 JSON 파일 통합 시작...\")\n",
    "    for file_path in file_list:\n",
    "        try:\n",
    "            base_name = os.path.basename(file_path)\n",
    "            # 파일명에서 카테고리 추출\n",
    "            category_part = base_name.replace('oliveyoung_', '').replace('_raw_limited.json', '')\n",
    "            category_name = category_part.replace('_', '/')\n",
    "\n",
    "            # encoding='utf-8' 명시\n",
    "            df = pd.read_json(file_path, encoding='utf-8')\n",
    "            df['카테고리'] = category_name\n",
    "            all_dfs.append(df)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"   ❌ 경고: 파일 '{file_path}'을 찾을 수 없습니다. 건너뜁니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ 경고: 파일 '{file_path}' 로드 중 오류 발생: {e}. 건너뜁니다.\")\n",
    "            \n",
    "    if not all_dfs:\n",
    "        print(\"   ❌ 오류: 로드된 올리브영 데이터가 없습니다. 스크립트를 종료합니다.\")\n",
    "        return None\n",
    "        \n",
    "    df_consolidated = pd.concat(all_dfs, ignore_index=True)\n",
    "    if '상품ID' not in df_consolidated.columns:\n",
    "        df_consolidated['상품ID'] = df_consolidated.index.astype(str)\n",
    "        \n",
    "    print(f\"✅ 총 {len(df_consolidated)}개 상품 통합 완료.\")\n",
    "    return df_consolidated\n",
    "\n",
    "def clean_and_standardize_coos(df_coos):\n",
    "    \"\"\"COOS 데이터를 클리닝하고 표준 매핑 키를 생성합니다.\"\"\"\n",
    "    print(\"\\n[1단계] COOS 성분 데이터 정리 및 표준화 시작...\")\n",
    "    \n",
    "    # COOS 파일의 실제 컬럼명 확인 및 기본값 설정\n",
    "    coos_name_col = '원료명'\n",
    "    coos_tag_col = '태그_목록'\n",
    "    coos_url_col = '상세_URL'\n",
    "    \n",
    "    if coos_name_col not in df_coos.columns:\n",
    "        coos_name_col = df_coos.columns[0] # 첫 번째 컬럼을 원료명으로 간주\n",
    "\n",
    "    df_coos['태그_목록_정리'] = df_coos[coos_tag_col].apply(clean_tags)\n",
    "    df_coos['표준성분명'] = df_coos[coos_name_col].apply(create_standard_name)\n",
    "    \n",
    "    # 2. 모델에 필요한 속성 컬럼 정의\n",
    "    coos_cols = ['표준성분명', coos_name_col, '영문명', 'CAS_No', '설명_요약', '태그_목록_정리', coos_url_col]\n",
    "    \n",
    "    # 실제 존재하는 컬럼만 선택\n",
    "    coos_cols_present = [col for col in coos_cols if col in df_coos.columns]\n",
    "\n",
    "    df_coos_clean = df_coos[coos_cols_present].rename(columns={\n",
    "        coos_name_col: 'COOS_원료명', \n",
    "        coos_url_col: 'COOS_상세_URL'\n",
    "        }).drop_duplicates(subset=['표준성분명'], keep='first')\n",
    "    \n",
    "    return df_coos_clean\n",
    "\n",
    "def verify_and_rename_ingredient_column(df, expected_col='성분_목록'):\n",
    "    \"\"\"\n",
    "    df에 필수 성분 컬럼이 있는지 확인하고, 없으면 대안 컬럼을 찾아 이름을 변경합니다.\n",
    "    \"\"\"\n",
    "    if expected_col in df.columns:\n",
    "        return df\n",
    "\n",
    "    ALTERNATIVE_NAMES = ['성분리스트', 'ingredients', '전성분', 'Ingredient_List', '성분목록']\n",
    "    \n",
    "    found_alt = None\n",
    "    for alt in ALTERNATIVE_NAMES:\n",
    "        if alt in df.columns:\n",
    "            df.rename(columns={alt: expected_col}, inplace=True)\n",
    "            print(f\"   ⚠️ 경고: '{expected_col}' 컬럼 대신 '{alt}' 컬럼을 사용하여 이름을 변경했습니다.\")\n",
    "            found_alt = True\n",
    "            break\n",
    "    \n",
    "    if not found_alt:\n",
    "        print(f\"   ❌ 치명적 오류: 통합된 올리브영 데이터에 필수 컬럼 '{expected_col}' 또는 그 대안이 없습니다.\")\n",
    "        print(f\"   현재 컬럼 목록: {df.columns.tolist()}\")\n",
    "        raise KeyError(expected_col) \n",
    "\n",
    "    return df\n",
    "\n",
    "def verify_and_rename_metadata_columns(df):\n",
    "    \"\"\"상품 메타데이터 컬럼 중 존재하는 컬럼(상품명)만 확인하고 표준화합니다.\"\"\"\n",
    "    REQUIRED_MAPPING = {'상품명': ['제품명', 'name', 'product_name']}\n",
    "    current_cols = df.columns.tolist()\n",
    "    \n",
    "    print(\"   [1.6단계] 메타데이터 컬럼 표준화 시작...\")\n",
    "\n",
    "    for expected, alternatives in REQUIRED_MAPPING.items():\n",
    "        if expected not in current_cols:\n",
    "            for alt in alternatives:\n",
    "                if alt in current_cols:\n",
    "                    df.rename(columns={alt: expected}, inplace=True)\n",
    "                    print(f\"      - '{alt}'을(를) '{expected}'으로(로) 변경했습니다.\")\n",
    "                    break\n",
    "    \n",
    "    print(\"   ✅ 메타데이터 표준화 완료 (상품명만 존재 확인).\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# --- 메인 실행 로직 ---\n",
    "# ----------------------------------------------------------------------\n",
    "def main():\n",
    "    \n",
    "    # 0. 데이터 로드\n",
    "    df_coos = None \n",
    "    coos_loaded = False\n",
    "    try:\n",
    "        # COOS 데이터는 CSV 파일이므로 pd.read_csv 사용\n",
    "        df_coos = pd.read_csv(COOS_FILE, encoding='utf-8')\n",
    "        print(f\"\\n[0.2단계] COOS 데이터 로드 완료: {len(df_coos)}개 성분\")\n",
    "        coos_loaded = True\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\n❌ 오류: COOS 파일 '{COOS_FILE}'을 찾을 수 없습니다. 성분 속성 병합 없이 올리브영 데이터만 정규화됩니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ 오류: COOS 파일 로드 중 예상치 못한 오류 발생: {e}\")\n",
    "\n",
    "\n",
    "    df_oly = load_and_consolidate_oliveyoung_data(OLIVE_YOUNG_FILES)\n",
    "    if df_oly is None: return\n",
    "\n",
    "    # 1.5단계: 필수 성분 컬럼 확인 및 이름 변경 (성분 목록 키 표준화)\n",
    "    try:\n",
    "        df_oly = verify_and_rename_ingredient_column(df_oly, expected_col='성분_목록')\n",
    "    except KeyError:\n",
    "        print(\"\\n   ⚠️ 데이터 오류로 인해 스크립트를 종료합니다. JSON 파일의 성분 목록 키를 확인하세요.\")\n",
    "        return \n",
    "    \n",
    "    # 1.6단계: 상품 메타데이터 컬럼 확인 및 이름 변경\n",
    "    df_oly = verify_and_rename_metadata_columns(df_oly)\n",
    "\n",
    "    \n",
    "    # 1. COOS 데이터 클리닝 및 표준화\n",
    "    if coos_loaded:\n",
    "        df_coos_clean = clean_and_standardize_coos(df_coos)\n",
    "    else:\n",
    "        df_coos_clean = pd.DataFrame()\n",
    "    \n",
    "    # 2. **업데이트된 핵심 로직:** 개별 상품 분리, 브랜드/제품명 파싱, 성분 폭발 및 매핑 키 생성\n",
    "    # >>>>> 누락되었던 함수 호출 <<<<<\n",
    "    df_oly_exploded = split_and_normalize_kit(df_oly)\n",
    "    \n",
    "    # 3. 올리브영 성분과 COOS 데이터 통합 (병합)\n",
    "    print(\"\\n[3단계] 성분 속성 연결을 위한 최종 데이터셋 병합...\")\n",
    "    \n",
    "    existing_oly_cols = ['상품ID', '상품명', '브랜드명', '제품명', '카테고리', 'URL', '사용_원료명', '표준_매핑_키']\n",
    "    \n",
    "    # 최종 결과에 포함할 컬럼 (순서 유지를 위해 리스트 사용)\n",
    "    # CAS_No는 COOS 데이터에만 있으므로 coos_loaded 여부에 관계없이 포함\n",
    "    final_columns = [\n",
    "        '상품ID', '브랜드명', '제품명', '카테고리', '사용_원료명', \n",
    "        'COOS_원료명', '영문명', '설명_요약', '태그_목록_정리', 'CAS_No', 'COOS_상세_URL', 'URL'\n",
    "    ]\n",
    "    \n",
    "    # 실제 df_oly_exploded에 존재하는 컬럼만 선택\n",
    "    df_oly_slim = df_oly_exploded[[col for col in existing_oly_cols if col in df_oly_exploded.columns]]\n",
    "\n",
    "    # 표준 매핑 키를 기준으로 COOS 속성 병합 (COOS 데이터가 있는 경우에만)\n",
    "    if coos_loaded:\n",
    "        df_final_normalized = df_oly_slim.merge(\n",
    "            df_coos_clean, \n",
    "            left_on='표준_매핑_키', \n",
    "            right_on='표준성분명', \n",
    "            how='left'\n",
    "        )\n",
    "        # 불필요한 임시 컬럼 제거\n",
    "        df_final_normalized.drop(columns=['표준성분명', '표준_매핑_키', '상품명'], inplace=True, errors='ignore') \n",
    "        df_final_normalized = df_final_normalized[[col for col in final_columns if col in df_final_normalized.columns]]\n",
    "    else:\n",
    "        # COOS 데이터가 없으면 병합 없이 올리브영 데이터만 정리\n",
    "        df_final_normalized = df_oly_slim.drop(columns=['표준_매핑_키', '상품명'], errors='ignore')\n",
    "        print(\"   ⚠️ COOS 파일 누락으로 성분 속성(COOS_원료명, 영문명, CAS_No 등) 없이 올리브영 데이터만 정규화됩니다.\")\n",
    "\n",
    "    print(f\"✅ 최종 통합 및 정규화된 데이터셋 크기: {len(df_final_normalized)} 행\")\n",
    "    \n",
    "    # 최종 CSV 파일 저장\n",
    "    df_final_normalized.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"\\n==================================================\")\n",
    "    print(f\"✅ 데이터 통합 및 정규화 완료!\")\n",
    "    print(f\"결과 파일: {OUTPUT_FILE}\")\n",
    "    print(\"브랜드명, 제품명, 개별 성분(COOS 속성 포함)을 기준으로 데이터가 완벽하게 정규화되었습니다.\")\n",
    "    print(\"==================================================\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# --- 메인 실행 블록 ---\n",
    "# ----------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20ee04ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.2단계] COOS 데이터 로드 완료: 25750개 성분\n",
      "\n",
      "[0.1단계] 올리브영 JSON 파일 통합 시작...\n",
      "✅ 총 2187개 상품 통합 완료.\n",
      "   ⚠️ 경고: '성분_목록' 컬럼 대신 '성분리스트' 컬럼을 사용하여 이름을 변경했습니다.\n",
      "   [1.6단계] 메타데이터 컬럼 표준화 시작...\n",
      "      - '제품명'을(를) '상품명'으로(로) 변경했습니다.\n",
      "   ✅ 메타데이터 표준화 완료 (상품명만 존재 확인).\n",
      "\n",
      "[1단계] COOS 성분 데이터 정리 및 표준화 시작...\n",
      "\n",
      "[2단계] 키트 분리, 성분 폭발, 표준화 시작...\n",
      "   ✅ 키트 분리 및 성분 폭발 완료. 총 92827개의 성분 레코드 생성.\n",
      "\n",
      "[3단계] 성분 속성 연결을 위한 최종 데이터셋 병합...\n",
      "✅ 최종 통합 및 정규화된 데이터셋 크기: 92827 행\n",
      "\n",
      "==================================================\n",
      "✅ 데이터 통합 및 정규화 완료!\n",
      "결과 파일: integrated_product_ingredient_normalized_2.csv\n",
      "브랜드명, 제품명, 개별 성분(COOS 속성 포함)을 기준으로 데이터가 완벽하게 정규화되었습니다.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "from itertools import combinations \n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# --- 설정 ---\n",
    "# ----------------------------------------------------------------------\n",
    "# COOS 데이터베이스 파일 (사용자 제공 파일명)\n",
    "COOS_FILE = \"coos_ingredient_database.csv\"\n",
    "\n",
    "# 올리브영 JSON 파일 목록 (사용자 제공 파일명)\n",
    "OLIVE_YOUNG_FILES = [\n",
    "    \"oliveyoung_로션_raw_limited.json\",\n",
    "    \"oliveyoung_미스트_오일_raw_limited.json\",\n",
    "    \"oliveyoung_스킨_토너_raw_limited.json\",\n",
    "    \"oliveyoung_에센스_세럼_앰플_raw_limited.json\",\n",
    "    \"oliveyoung_크림_raw_limited.json\",\n",
    "]\n",
    "OUTPUT_FILE = \"integrated_product_ingredient_normalized_2.csv\"\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# --- 데이터 클리닝 유틸리티 (Normalization Functions) ---\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def clean_tags(tags):\n",
    "    \"\"\"COOS 데이터의 태그 목록에서 불필요한 노이즈를 제거합니다.\"\"\"\n",
    "    if not isinstance(tags, str): return \"\"\n",
    "    tags_list = [t.strip() for t in tags.split(',')]\n",
    "    # EWG-Green 태그는 남기고, EWG 등 불필요한 패턴 제거\n",
    "    NOISE_PATTERNS = re.compile(r'^(AI|KO|EN|JP|EU|식|가능|불가|EWG|EWG-Green)$', re.IGNORECASE)\n",
    "    cleaned_tags = [t for t in tags_list if t and len(t) > 2 and not NOISE_PATTERNS.match(t)]\n",
    "    return ', '.join(cleaned_tags)\n",
    "\n",
    "def create_standard_name(name):\n",
    "    \"\"\"성분명에서 특수문자 등을 제거하고 소문자화하여 표준 매핑 키(Standard Key)를 만듭니다.\"\"\"\n",
    "    if not isinstance(name, str): return None\n",
    "    # 괄호와 그 안의 내용 제거 (예: 정제수(달팽이점액여과물) -> 정제수)\n",
    "    name = re.sub(r'\\(.*?\\)', '', name).strip()\n",
    "    # 문자, 숫자, 한글, 영어 외의 모든 문자를 공백으로 치환 후 제거\n",
    "    cleaned_name = re.sub(r'[^\\w가-힣]+', '', name).lower()\n",
    "    return cleaned_name\n",
    "\n",
    "def parse_brand_and_name(full_name):\n",
    "    \"\"\"\n",
    "    상품명에서 불필요한 기획/증정 정보를 제거하고 브랜드와 제품명을 분리합니다.\n",
    "    \"\"\"\n",
    "    if not isinstance(full_name, str):\n",
    "        return None, None\n",
    "    \n",
    "    # 1. []나 () 안에 있는 노이즈 제거 (예: [1등올인원], (+100ml증정))\n",
    "    cleaned_name = re.sub(r'\\[.*?\\]|\\(.*?\\)', '', full_name).strip()\n",
    "    \n",
    "    # 2. '기획세트', '세트', '증정', '대용량', '본품' 등 상품의 특성 관련 단어 제거\n",
    "    noise_words = ['기획세트', '기획', '세트', '증정', '대용량', '본품', '단품']\n",
    "    for word in noise_words:\n",
    "        cleaned_name = cleaned_name.replace(word, ' ').strip()\n",
    "    \n",
    "    # 여러 개의 공백을 하나로 줄임\n",
    "    cleaned_name = re.sub(r'\\s+', ' ', cleaned_name).strip()\n",
    "    \n",
    "    # 3. 브랜드명 (첫 번째 단어) 추출 및 제품명 (나머지 부분) 추출\n",
    "    parts = cleaned_name.split(maxsplit=1)\n",
    "    brand = parts[0] if parts else None\n",
    "    product_name = parts[1].strip() if len(parts) > 1 else None\n",
    "    \n",
    "    return brand, product_name\n",
    "\n",
    "def preprocess_mushed_ingredients(full_string):\n",
    "    \"\"\"\n",
    "    붙어버린 성분 경계를 복구하고, 키트 마커를 정리합니다.\n",
    "    (예: '토코페롤정제수' -> '토코페롤,정제수')\n",
    "    \"\"\"\n",
    "    # 1. 흔한 시작 성분 그룹: 이 성분들이 이전 성분이나 제품명에 붙어있을 확률이 높음\n",
    "    START_INGREDIENT_GROUP = r'(정제수|글리세린|다이카프릴릴|나이아신아마이드|메틸프로판다이올|부틸렌글라이콜|프로판다이올|펜틸렌글라이콜|스쿠알란|판테놀|토코페롤|아데노신|시트릭애씨드|소듐클로라이드|세테아릴|시트릭애씨드)'\n",
    "    \n",
    "    # 2. 정규식 패턴: (\\w) (한글,영문,숫자) 뒤에 바로 (흔한 시작 성분)이 붙어있는 경우\n",
    "    regex = re.compile(r'(\\w)' + START_INGREDIENT_GROUP, re.UNICODE)\n",
    "    \n",
    "    # 3. 찾은 패턴을 '성분1,성분2' 형태로 대체하여 쉼표를 삽입합니다.\n",
    "    processed_string = regex.sub(r'\\1,\\2', full_string)\n",
    "    \n",
    "    # 4. 키트 제품명 마커 정리: '제품명:정제수' 형태에서 콜론 뒤에 쉼표가 없으면 추가하여 분리하기 쉽게 만듭니다.\n",
    "    processed_string = re.sub(r'([가-힣\\s]+?)\\s*:\\s*([가-힣])', r'\\1,\\2', processed_string) # 콜론을 쉼표로 변환\n",
    "\n",
    "    # 5. 불필요한 공백/개행 문자 제거 및 정리\n",
    "    processed_string = re.sub(r'\\s{2,}', ' ', processed_string).replace('\\n', ' ').strip()\n",
    "    \n",
    "    # 6. 추가 정제: 쉼표 주변의 불필요한 공백 제거\n",
    "    processed_string = re.sub(r'\\s*,\\s*', ',', processed_string)\n",
    "    \n",
    "    return processed_string\n",
    "\n",
    "def split_kit_string(ingredient_list_or_str):\n",
    "    \"\"\"\n",
    "    제품명:성분리스트가 합쳐진 문자열을 파싱하여 개별 제품 레코드를 반환합니다.\n",
    "    (콜론, 대괄호 기반 마커 분리 로직 사용)\n",
    "    \"\"\"\n",
    "    if isinstance(ingredient_list_or_str, list):\n",
    "        # ***** CRITICAL FIX START *****\n",
    "        # 리스트 원소들을 공백 대신 쉼표(,)로 연결해야 개별 성분으로 분리 가능\n",
    "        full_string = \",\".join([str(item).strip() for item in ingredient_list_or_str if str(item).strip()]).strip()\n",
    "        # ***** CRITICAL FIX END *****\n",
    "    elif isinstance(ingredient_list_or_str, str):\n",
    "        full_string = ingredient_list_or_str.strip()\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "    if not full_string:\n",
    "        return []\n",
    "        \n",
    "    # 1. **전처리:** 붙어버린 성분 경계를 복구합니다.\n",
    "    full_string = preprocess_mushed_ingredients(full_string)\n",
    "    \n",
    "    # 2. 키트 마커 패턴: '[제품명]' (대괄호)\n",
    "    # 콜론은 preprocess_mushed_ingredients에서 쉼표로 변환되었으므로 대괄호만 마커로 사용\n",
    "    KIT_MARKER_PATTERN = r'(\\[.*?\\])'\n",
    "    \n",
    "    # 마커를 기준으로 분할하고, 마커 자체를 포함하도록 정규식 그룹을 사용\n",
    "    parts = re.split(KIT_MARKER_PATTERN, full_string)\n",
    "    \n",
    "    products = []\n",
    "    current_product_name = None\n",
    "    current_ingredients_str = \"\"\n",
    "    \n",
    "    # 분할된 문자열 처리\n",
    "    for part in parts:\n",
    "        if not part or part.isspace():\n",
    "            continue\n",
    "            \n",
    "        # 3. 제품명 마커 확인\n",
    "        \n",
    "        # Case 1: '[제품명]' 형태의 마커\n",
    "        if part.startswith('[') and part.endswith(']'):\n",
    "            # 이전 제품의 성분을 처리하고 새 제품 시작\n",
    "            if current_ingredients_str and current_product_name:\n",
    "                # 쉼표를 기준으로 성분 분리\n",
    "                ingredients = [ing.strip() for ing in current_ingredients_str.split(',') if ing.strip()]\n",
    "                products.append({'name': current_product_name, 'ingredients': ingredients})\n",
    "                current_ingredients_str = \"\"\n",
    "            \n",
    "            current_product_name = part.strip().strip('[]').strip()\n",
    "            \n",
    "        # Case 2: 성분 문자열 (쉼표로 구분됨)\n",
    "        else:\n",
    "            # 성분 덩어리가 공백으로 시작하면 제거 (키트 마커 잔여물 방지)\n",
    "            current_ingredients_str += part.lstrip()\n",
    "            \n",
    "    # 4. 마지막 제품의 성분 처리\n",
    "    if current_ingredients_str:\n",
    "        # 쉼표를 기준으로 성분 분리\n",
    "        ingredients = [ing.strip() for ing in current_ingredients_str.split(',') if ing.strip()]\n",
    "        \n",
    "        if not products and not current_product_name:\n",
    "             # 키트 마커 없이 단일 제품으로 인식\n",
    "             products.append({'name': None, 'ingredients': ingredients})\n",
    "        elif current_product_name:\n",
    "             # 마커가 있었던 마지막 제품\n",
    "             products.append({'name': current_product_name, 'ingredients': ingredients})\n",
    "        else:\n",
    "            # 마커는 없는데 데이터가 남은 경우 (단일 제품으로 강제 처리)\n",
    "            products.append({'name': None, 'ingredients': ingredients})\n",
    "            \n",
    "    return products\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# --- 핵심 정규화 로직 함수 ---\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def split_and_normalize_kit(df_oly):\n",
    "    \"\"\"\n",
    "    올리브영 데이터프레임을 받아, 키트 제품을 개별 상품으로 분리하고,\n",
    "    각 성분을 행으로 폭발(Explode)시켜 최종 정규화된 데이터프레임을 반환합니다.\n",
    "    \"\"\"\n",
    "    print(\"\\n[2단계] 키트 분리, 성분 폭발, 표준화 시작...\")\n",
    "    \n",
    "    all_normalized_products = []\n",
    "    \n",
    "    for index, row in df_oly.iterrows():\n",
    "        # 1. 키트 분리 및 성분 추출\n",
    "        kit_products = split_kit_string(row['성분_목록'])\n",
    "        \n",
    "        # 2. 브랜드명 (원래 상품명 기준) 및 제품명(키트 분리 결과) 파싱\n",
    "        original_product_name = row['상품명']\n",
    "        original_brand, parsed_product_name = parse_brand_and_name(original_product_name)\n",
    "        \n",
    "        # 키트 분리 결과에 따라 반복 처리\n",
    "        for kit_item in kit_products:\n",
    "            # 최종 제품명 결정: 키트 분리 시 이름이 있으면 사용, 없으면 원본에서 파싱된 제품명 사용\n",
    "            final_product_name = kit_item['name'] if kit_item['name'] else parsed_product_name\n",
    "            \n",
    "            # 3. 개별 성분 폭발 및 매핑 키 생성\n",
    "            for ingredient in kit_item['ingredients']:\n",
    "                if ingredient:\n",
    "                    # 성분 데이터 레코드 생성\n",
    "                    record = {\n",
    "                        '상품ID': row.get('상품ID'),\n",
    "                        '상품명': original_product_name, # 원본 상품명 유지\n",
    "                        '브랜드명': original_brand,\n",
    "                        '제품명': final_product_name, # 정규화된 개별 제품명\n",
    "                        '카테고리': row.get('카테고리'),\n",
    "                        'URL': row.get('URL'),\n",
    "                        '사용_원료명': ingredient, # 올리브영 성분명 (개별 성분)\n",
    "                        '표준_매핑_키': create_standard_name(ingredient) # COOS 매핑을 위한 표준 키\n",
    "                    }\n",
    "                    all_normalized_products.append(record)\n",
    "\n",
    "    df_normalized = pd.DataFrame(all_normalized_products)\n",
    "    print(f\"   ✅ 키트 분리 및 성분 폭발 완료. 총 {len(df_normalized)}개의 성분 레코드 생성.\")\n",
    "    return df_normalized\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# --- 데이터 로딩 및 통합 함수 ---\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def load_and_consolidate_oliveyoung_data(file_list):\n",
    "    \"\"\"여러 올리브영 JSON 파일을 통합하고 카테고리 정보를 추가합니다.\"\"\"\n",
    "    all_dfs = []\n",
    "    print(\"\\n[0.1단계] 올리브영 JSON 파일 통합 시작...\")\n",
    "    for file_path in file_list:\n",
    "        try:\n",
    "            base_name = os.path.basename(file_path)\n",
    "            # 파일명에서 카테고리 추출\n",
    "            category_part = base_name.replace('oliveyoung_', '').replace('_raw_limited.json', '')\n",
    "            category_name = category_part.replace('_', '/')\n",
    "\n",
    "            # encoding='utf-8' 명시\n",
    "            df = pd.read_json(file_path, encoding='utf-8')\n",
    "            df['카테고리'] = category_name\n",
    "            all_dfs.append(df)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"   ❌ 경고: 파일 '{file_path}'을 찾을 수 없습니다. 건너뜁니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ 경고: 파일 '{file_path}' 로드 중 오류 발생: {e}. 건너뜁니다.\")\n",
    "            \n",
    "    if not all_dfs:\n",
    "        print(\"   ❌ 오류: 로드된 올리브영 데이터가 없습니다. 스크립트를 종료합니다.\")\n",
    "        return None\n",
    "        \n",
    "    df_consolidated = pd.concat(all_dfs, ignore_index=True)\n",
    "    if '상품ID' not in df_consolidated.columns:\n",
    "        df_consolidated['상품ID'] = df_consolidated.index.astype(str)\n",
    "        \n",
    "    print(f\"✅ 총 {len(df_consolidated)}개 상품 통합 완료.\")\n",
    "    return df_consolidated\n",
    "\n",
    "def clean_and_standardize_coos(df_coos):\n",
    "    \"\"\"COOS 데이터를 클리닝하고 표준 매핑 키를 생성합니다.\"\"\"\n",
    "    print(\"\\n[1단계] COOS 성분 데이터 정리 및 표준화 시작...\")\n",
    "    \n",
    "    # COOS 파일의 실제 컬럼명 확인 및 기본값 설정\n",
    "    coos_name_col = '원료명'\n",
    "    coos_tag_col = '태그_목록'\n",
    "    coos_url_col = '상세_URL'\n",
    "    \n",
    "    if coos_name_col not in df_coos.columns:\n",
    "        coos_name_col = df_coos.columns[0] # 첫 번째 컬럼을 원료명으로 간주\n",
    "\n",
    "    df_coos['태그_목록_정리'] = df_coos[coos_tag_col].apply(clean_tags)\n",
    "    df_coos['표준성분명'] = df_coos[coos_name_col].apply(create_standard_name)\n",
    "    \n",
    "    # 2. 모델에 필요한 속성 컬럼 정의\n",
    "    coos_cols = ['표준성분명', coos_name_col, '영문명', 'CAS_No', '설명_요약', '태그_목록_정리', coos_url_col]\n",
    "    \n",
    "    # 실제 존재하는 컬럼만 선택\n",
    "    coos_cols_present = [col for col in coos_cols if col in df_coos.columns]\n",
    "\n",
    "    df_coos_clean = df_coos[coos_cols_present].rename(columns={\n",
    "        coos_name_col: 'COOS_원료명', \n",
    "        coos_url_col: 'COOS_상세_URL'\n",
    "        }).drop_duplicates(subset=['표준성분명'], keep='first')\n",
    "    \n",
    "    return df_coos_clean\n",
    "\n",
    "def verify_and_rename_ingredient_column(df, expected_col='성분_목록'):\n",
    "    \"\"\"\n",
    "    df에 필수 성분 컬럼이 있는지 확인하고, 없으면 대안 컬럼을 찾아 이름을 변경합니다.\n",
    "    \"\"\"\n",
    "    if expected_col in df.columns:\n",
    "        return df\n",
    "\n",
    "    ALTERNATIVE_NAMES = ['성분리스트', 'ingredients', '전성분', 'Ingredient_List', '성분목록']\n",
    "    \n",
    "    found_alt = None\n",
    "    for alt in ALTERNATIVE_NAMES:\n",
    "        if alt in df.columns:\n",
    "            df.rename(columns={alt: expected_col}, inplace=True)\n",
    "            print(f\"   ⚠️ 경고: '{expected_col}' 컬럼 대신 '{alt}' 컬럼을 사용하여 이름을 변경했습니다.\")\n",
    "            found_alt = True\n",
    "            break\n",
    "    \n",
    "    if not found_alt:\n",
    "        print(f\"   ❌ 치명적 오류: 통합된 올리브영 데이터에 필수 컬럼 '{expected_col}' 또는 그 대안이 없습니다.\")\n",
    "        print(f\"   현재 컬럼 목록: {df.columns.tolist()}\")\n",
    "        raise KeyError(expected_col) \n",
    "\n",
    "    return df\n",
    "\n",
    "def verify_and_rename_metadata_columns(df):\n",
    "    \"\"\"상품 메타데이터 컬럼 중 존재하는 컬럼(상품명)만 확인하고 표준화합니다.\"\"\"\n",
    "    REQUIRED_MAPPING = {'상품명': ['제품명', 'name', 'product_name']}\n",
    "    current_cols = df.columns.tolist()\n",
    "    \n",
    "    print(\"   [1.6단계] 메타데이터 컬럼 표준화 시작...\")\n",
    "\n",
    "    for expected, alternatives in REQUIRED_MAPPING.items():\n",
    "        if expected not in current_cols:\n",
    "            for alt in alternatives:\n",
    "                if alt in current_cols:\n",
    "                    df.rename(columns={alt: expected}, inplace=True)\n",
    "                    print(f\"      - '{alt}'을(를) '{expected}'으로(로) 변경했습니다.\")\n",
    "                    break\n",
    "    \n",
    "    print(\"   ✅ 메타데이터 표준화 완료 (상품명만 존재 확인).\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# --- 메인 실행 로직 ---\n",
    "# ----------------------------------------------------------------------\n",
    "def main():\n",
    "    \n",
    "    # 0. 데이터 로드\n",
    "    df_coos = None \n",
    "    coos_loaded = False\n",
    "    try:\n",
    "        # COOS 데이터는 CSV 파일이므로 pd.read_csv 사용\n",
    "        df_coos = pd.read_csv(COOS_FILE, encoding='utf-8')\n",
    "        print(f\"\\n[0.2단계] COOS 데이터 로드 완료: {len(df_coos)}개 성분\")\n",
    "        coos_loaded = True\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\n❌ 오류: COOS 파일 '{COOS_FILE}'을 찾을 수 없습니다. 성분 속성 병합 없이 올리브영 데이터만 정규화됩니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ 오류: COOS 파일 로드 중 예상치 못한 오류 발생: {e}\")\n",
    "\n",
    "\n",
    "    df_oly = load_and_consolidate_oliveyoung_data(OLIVE_YOUNG_FILES)\n",
    "    if df_oly is None: return\n",
    "\n",
    "    # 1.5단계: 필수 성분 컬럼 확인 및 이름 변경 (성분 목록 키 표준화)\n",
    "    try:\n",
    "        df_oly = verify_and_rename_ingredient_column(df_oly, expected_col='성분_목록')\n",
    "    except KeyError:\n",
    "        print(\"\\n   ⚠️ 데이터 오류로 인해 스크립트를 종료합니다. JSON 파일의 성분 목록 키를 확인하세요.\")\n",
    "        return \n",
    "    \n",
    "    # 1.6단계: 상품 메타데이터 컬럼 확인 및 이름 변경\n",
    "    df_oly = verify_and_rename_metadata_columns(df_oly)\n",
    "\n",
    "    \n",
    "    # 1. COOS 데이터 클리닝 및 표준화\n",
    "    if coos_loaded:\n",
    "        df_coos_clean = clean_and_standardize_coos(df_coos)\n",
    "    else:\n",
    "        df_coos_clean = pd.DataFrame()\n",
    "    \n",
    "    # 2. **업데이트된 핵심 로직:** 개별 상품 분리, 브랜드/제품명 파싱, 성분 폭발 및 매핑 키 생성\n",
    "    df_oly_exploded = split_and_normalize_kit(df_oly)\n",
    "    \n",
    "    # 3. 올리브영 성분과 COOS 데이터 통합 (병합)\n",
    "    print(\"\\n[3단계] 성분 속성 연결을 위한 최종 데이터셋 병합...\")\n",
    "    \n",
    "    existing_oly_cols = ['상품ID', '상품명', '브랜드명', '제품명', '카테고리', 'URL', '사용_원료명', '표준_매핑_키']\n",
    "    \n",
    "    # 최종 결과에 포함할 컬럼 (순서 유지를 위해 리스트 사용)\n",
    "    final_columns = [\n",
    "        '상품ID', '브랜드명', '제품명', '카테고리', '사용_원료명', \n",
    "        'COOS_원료명', '영문명', '설명_요약', '태그_목록_정리', 'CAS_No', 'COOS_상세_URL', 'URL'\n",
    "    ]\n",
    "    \n",
    "    # 실제 df_oly_exploded에 존재하는 컬럼만 선택\n",
    "    df_oly_slim = df_oly_exploded[[col for col in existing_oly_cols if col in df_oly_exploded.columns]]\n",
    "\n",
    "    # 표준 매핑 키를 기준으로 COOS 속성 병합 (COOS 데이터가 있는 경우에만)\n",
    "    if coos_loaded:\n",
    "        df_final_normalized = df_oly_slim.merge(\n",
    "            df_coos_clean, \n",
    "            left_on='표준_매핑_키', \n",
    "            right_on='표준성분명', \n",
    "            how='left'\n",
    "        )\n",
    "        # 불필요한 임시 컬럼 제거\n",
    "        df_final_normalized.drop(columns=['표준성분명', '표준_매핑_키', '상품명'], inplace=True, errors='ignore') \n",
    "        df_final_normalized = df_final_normalized[[col for col in final_columns if col in df_final_normalized.columns]]\n",
    "    else:\n",
    "        # COOS 데이터가 없으면 병합 없이 올리브영 데이터만 정리\n",
    "        df_final_normalized = df_oly_slim.drop(columns=['표준_매핑_키', '상품명'], errors='ignore')\n",
    "        print(\"   ⚠️ COOS 파일 누락으로 성분 속성(COOS_원료명, 영문명, CAS_No 등) 없이 올리브영 데이터만 정규화됩니다.\")\n",
    "\n",
    "    print(f\"✅ 최종 통합 및 정규화된 데이터셋 크기: {len(df_final_normalized)} 행\")\n",
    "    \n",
    "    # 최종 CSV 파일 저장\n",
    "    df_final_normalized.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"\\n==================================================\")\n",
    "    print(f\"✅ 데이터 통합 및 정규화 완료!\")\n",
    "    print(f\"결과 파일: {OUTPUT_FILE}\")\n",
    "    print(\"브랜드명, 제품명, 개별 성분(COOS 속성 포함)을 기준으로 데이터가 완벽하게 정규화되었습니다.\")\n",
    "    print(\"==================================================\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# --- 메인 실행 블록 ---\n",
    "# ----------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
